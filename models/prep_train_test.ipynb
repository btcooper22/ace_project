{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "ace_data = pd.read_pickle(\"../data/../data/ace_data_extra_feats.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 499 entries, 0 to 498\n",
      "Data columns (total 28 columns):\n",
      " #   Column               Non-Null Count  Dtype   \n",
      "---  ------               --------------  -----   \n",
      " 0   hospital_reqd        499 non-null    int64   \n",
      " 1   referral_from        498 non-null    category\n",
      " 2   age                  499 non-null    int64   \n",
      " 3   address              499 non-null    category\n",
      " 4   gender               499 non-null    category\n",
      " 5   referral_date        499 non-null    category\n",
      " 6   referral_time        499 non-null    category\n",
      " 7   illness_severity     497 non-null    category\n",
      " 8   activity_level       496 non-null    category\n",
      " 9   gut_feeling          494 non-null    category\n",
      " 10  ox_sat               489 non-null    float64 \n",
      " 11  resp_rate            488 non-null    float64 \n",
      " 12  heart_rate           490 non-null    float64 \n",
      " 13  temp                 438 non-null    float64 \n",
      " 14  sepsis               499 non-null    category\n",
      " 15  safeguarding         499 non-null    category\n",
      " 16  food_allergy         499 non-null    category\n",
      " 17  drug_allergy         499 non-null    category\n",
      " 18  other_allergy        499 non-null    category\n",
      " 19  simple_ethnicity     499 non-null    category\n",
      " 20  group_ethnicity      499 non-null    category\n",
      " 21  ox_sat_low           499 non-null    category\n",
      " 22  age_range            499 non-null    category\n",
      " 23  ace_heart_rate_cat   499 non-null    category\n",
      " 24  ace_resp_rate_cat    499 non-null    category\n",
      " 25  meets_ace_criteria   499 non-null    category\n",
      " 26  apls_heart_rate_cat  499 non-null    category\n",
      " 27  apls_resp_rate_cat   499 non-null    category\n",
      "dtypes: category(22), float64(4), int64(2)\n",
      "memory usage: 34.8 KB\n"
     ]
    }
   ],
   "source": [
    "ace_data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   hospital_reqd referral_from  age address gender referral_date  \\\n0              0          CCDA    8    BD07      F        Winter   \n1              0           A&E   11    BD03      F        Winter   \n2              0          CCDA    3    BD04      F        Winter   \n3              0            GP    3    BD06      M        Winter   \n4              0            GP    3    BD09      M        Winter   \n\n  referral_time illness_severity activity_level  gut_feeling  ...  \\\n0       Morning         Moderate          usual  low concern  ...   \n1       Morning             Mild          lower  low concern  ...   \n2     Afternoon             Mild          usual         well  ...   \n3     Afternoon             Mild          usual  low concern  ...   \n4     Afternoon             Mild          usual         well  ...   \n\n   other_allergy  simple_ethnicity  group_ethnicity  ox_sat_low   age_range  \\\n0              N             other            asian           N     primary   \n1              N         Pakistani            asian           N     primary   \n2              N             other         european           N  pre_school   \n3              N           British         european           N  pre_school   \n4              N         Pakistani            asian           N  pre_school   \n\n  ace_heart_rate_cat ace_resp_rate_cat meets_ace_criteria apls_heart_rate_cat  \\\n0             normal            normal                  N              normal   \n1             normal            normal                  Y              normal   \n2             normal            normal                  Y              normal   \n3             normal            normal                  Y              normal   \n4             normal            normal                  Y              normal   \n\n  apls_resp_rate_cat  \n0             normal  \n1             normal  \n2             normal  \n3             normal  \n4             normal  \n\n[5 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hospital_reqd</th>\n      <th>referral_from</th>\n      <th>age</th>\n      <th>address</th>\n      <th>gender</th>\n      <th>referral_date</th>\n      <th>referral_time</th>\n      <th>illness_severity</th>\n      <th>activity_level</th>\n      <th>gut_feeling</th>\n      <th>...</th>\n      <th>other_allergy</th>\n      <th>simple_ethnicity</th>\n      <th>group_ethnicity</th>\n      <th>ox_sat_low</th>\n      <th>age_range</th>\n      <th>ace_heart_rate_cat</th>\n      <th>ace_resp_rate_cat</th>\n      <th>meets_ace_criteria</th>\n      <th>apls_heart_rate_cat</th>\n      <th>apls_resp_rate_cat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>CCDA</td>\n      <td>8</td>\n      <td>BD07</td>\n      <td>F</td>\n      <td>Winter</td>\n      <td>Morning</td>\n      <td>Moderate</td>\n      <td>usual</td>\n      <td>low concern</td>\n      <td>...</td>\n      <td>N</td>\n      <td>other</td>\n      <td>asian</td>\n      <td>N</td>\n      <td>primary</td>\n      <td>normal</td>\n      <td>normal</td>\n      <td>N</td>\n      <td>normal</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>A&amp;E</td>\n      <td>11</td>\n      <td>BD03</td>\n      <td>F</td>\n      <td>Winter</td>\n      <td>Morning</td>\n      <td>Mild</td>\n      <td>lower</td>\n      <td>low concern</td>\n      <td>...</td>\n      <td>N</td>\n      <td>Pakistani</td>\n      <td>asian</td>\n      <td>N</td>\n      <td>primary</td>\n      <td>normal</td>\n      <td>normal</td>\n      <td>Y</td>\n      <td>normal</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>CCDA</td>\n      <td>3</td>\n      <td>BD04</td>\n      <td>F</td>\n      <td>Winter</td>\n      <td>Afternoon</td>\n      <td>Mild</td>\n      <td>usual</td>\n      <td>well</td>\n      <td>...</td>\n      <td>N</td>\n      <td>other</td>\n      <td>european</td>\n      <td>N</td>\n      <td>pre_school</td>\n      <td>normal</td>\n      <td>normal</td>\n      <td>Y</td>\n      <td>normal</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>GP</td>\n      <td>3</td>\n      <td>BD06</td>\n      <td>M</td>\n      <td>Winter</td>\n      <td>Afternoon</td>\n      <td>Mild</td>\n      <td>usual</td>\n      <td>low concern</td>\n      <td>...</td>\n      <td>N</td>\n      <td>British</td>\n      <td>european</td>\n      <td>N</td>\n      <td>pre_school</td>\n      <td>normal</td>\n      <td>normal</td>\n      <td>Y</td>\n      <td>normal</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>GP</td>\n      <td>3</td>\n      <td>BD09</td>\n      <td>M</td>\n      <td>Winter</td>\n      <td>Afternoon</td>\n      <td>Mild</td>\n      <td>usual</td>\n      <td>well</td>\n      <td>...</td>\n      <td>N</td>\n      <td>Pakistani</td>\n      <td>asian</td>\n      <td>N</td>\n      <td>pre_school</td>\n      <td>normal</td>\n      <td>normal</td>\n      <td>Y</td>\n      <td>normal</td>\n      <td>normal</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 28 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ace_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## split data into examples with nas and complete examples:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "na_examples_mask = ace_data.isna().any(axis=1)\n",
    "na_ace_data = ace_data[na_examples_mask]\n",
    "clean_ace_data = ace_data[~na_examples_mask]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## train test split the examples without na values:\n",
    "\n",
    "maintain proportion of hospital required examples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    clean_ace_data.drop(\"hospital_reqd\", axis=1),\n",
    "    clean_ace_data.hospital_reqd,\n",
    "    test_size=0.33,\n",
    "    stratify=clean_ace_data.hospital_reqd,\n",
    "    random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## explore and clean the na data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 examples are missing 1 features\n",
      "14 require hospital treatment\n",
      "\n",
      "3 examples are missing 2 features\n",
      "0 require hospital treatment\n",
      "\n",
      "2 examples are missing 3 features\n",
      "0 require hospital treatment\n",
      "\n",
      "6 examples are missing 4 features\n",
      "0 require hospital treatment\n",
      "\n",
      "1 examples are missing 7 features\n",
      "0 require hospital treatment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "na_counts = na_ace_data.isna().sum(axis=1)\n",
    "for i in sorted(na_counts.unique()):\n",
    "    print(f\"{sum(na_counts == i)} examples are missing {i} features\")\n",
    "    print(f\"{na_ace_data[na_counts == i].hospital_reqd.sum()} require hospital treatment\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "there are 12 examples that have more than one nan value - all of these are children\n",
    "not requiring hospital care - therefore remove\n",
    "\n",
    "other examples with only one na value: na can be inferred from age group mean and added"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 examples are missing activity_level\n",
      "\n",
      "3 examples are missing gut_feeling\n",
      "\n",
      "2 examples are missing ox_sat\n",
      "\n",
      "2 examples are missing resp_rate\n",
      "\n",
      "1 examples are missing heart_rate\n",
      "\n",
      "50 examples are missing temp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "na_ace_data = na_ace_data[na_counts == 1]\n",
    "missing_features = na_ace_data.isna().sum(axis=0)\n",
    "\n",
    "for feature in missing_features.index:\n",
    "    if missing_features[feature] > 0:\n",
    "        print(f\"{missing_features[feature]} examples are missing {feature}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "activity_level and gut_feeling can be set to overall mode"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "activity_is_na = na_ace_data.activity_level.isna()\n",
    "na_ace_data.loc[activity_is_na, \"activity_level\"] = ace_data.activity_level.mode()[0]\n",
    "\n",
    "gut_is_na = na_ace_data.gut_feeling.isna()\n",
    "na_ace_data.loc[gut_is_na, \"gut_feeling\"] = ace_data.gut_feeling.mode().values[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ox_sat and temp can be set to overall mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "ox_is_na = na_ace_data.ox_sat.isna()\n",
    "na_ace_data.loc[ox_is_na, \"ox_sat\"] = ace_data.ox_sat.mean()\n",
    "\n",
    "temp_is_na = na_ace_data.temp.isna()\n",
    "na_ace_data.loc[temp_is_na, \"temp\"] = ace_data.temp.mean()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "heart_rate and resp rate can be set to mean for age_range"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "hr_is_na = na_ace_data.heart_rate.isna()\n",
    "na_ace_data.loc[hr_is_na, \"heart_rate\"] = na_ace_data[hr_is_na][\"age_range\"].apply(\n",
    "   lambda age_range: ace_data[ace_data.age_range == age_range].heart_rate.mean()\n",
    ").astype(\"float\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "resp_is_na = na_ace_data.resp_rate.isna()\n",
    "na_ace_data.loc[resp_is_na, \"resp_rate\"] = na_ace_data[resp_is_na][\"age_range\"].apply(\n",
    "   lambda age_range: ace_data[ace_data.age_range == age_range].resp_rate.mean()\n",
    ").astype(\"float\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "concat na_examples / labels to X_train / y_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, na_ace_data.drop(\"hospital_reqd\", axis=1)])\n",
    "y_train = pd.concat([y_train, na_ace_data.hospital_reqd])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Oversampling to address imbalance in positive / negative hospital required\n",
    "\n",
    "oversample X_train using SMOTE from imblearn package"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "cat_feature_idxs = []\n",
    "for i, col in enumerate(X_train.columns):\n",
    "    if not X_train[col].dtype in [\"int\", \"float\"]:\n",
    "        cat_feature_idxs.append(i)\n",
    "\n",
    "smote = SMOTENC(random_state=1,\n",
    "                categorical_features=cat_feature_idxs)\n",
    "\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One Hot Encode Features for numeric modelling methods\n",
    "## include scaled versions of data for models that will benefit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "cat_features = [feature for feature in X_train.columns\n",
    "                    if X_train[feature].dtype.name == \"category\"\n",
    "                    and feature != \"ethnicity\"]\n",
    "\n",
    "num_features = [feature for feature in X_train.columns\n",
    "                if feature not in cat_features\n",
    "                and feature != \"ethnicity\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "mm_scaler = MinMaxScaler().fit(X_train[num_features])\n",
    "\n",
    "oh_enc = OneHotEncoder(sparse=False).fit(X_train[cat_features])\n",
    "\n",
    "one_hot_feature_names = []\n",
    "for feature, categories in zip(cat_features, oh_enc.categories_):\n",
    "    for category in categories:\n",
    "        name = feature + '_' + category\n",
    "        one_hot_feature_names.append(name)\n",
    "\n",
    "ohe_dfs = []\n",
    "scaled_ohe_dfs = []\n",
    "for df in [X_train, X_train_res, X_test]:\n",
    "    oh_data = pd.DataFrame(oh_enc.transform(df[cat_features]),\n",
    "                           columns=one_hot_feature_names)\n",
    "    num_data = df[num_features].reset_index(drop=True)\n",
    "    scaled_num_data = pd.DataFrame(mm_scaler.transform(num_data),\n",
    "                                   columns=num_features)\n",
    "\n",
    "    df_ohe = pd.concat([oh_data, num_data], axis=1)\n",
    "    ohe_dfs.append(df_ohe)\n",
    "\n",
    "    df_ohe_scaled = pd.concat([oh_data, scaled_num_data], axis=1)\n",
    "    scaled_ohe_dfs.append(df_ohe_scaled)\n",
    "\n",
    "X_train_ohe, X_train_res_ohe, X_test_ohe = ohe_dfs\n",
    "X_train_ohe_scaled, X_train_res_ohe_scaled, X_test_ohe_scaled = scaled_ohe_dfs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Target encode categorical features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samface/anaconda3/envs/ace_env/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "\n",
    "target_enc = LeaveOneOutEncoder(cols=cat_features).fit(X_train, y_train)\n",
    "\n",
    "target_encd_dfs = []\n",
    "scaled_target_encd_dfs = []\n",
    "for df in [X_train, X_train_res, X_test]:\n",
    "    target_encd_df = target_enc.transform(df).reset_index(drop=True)\n",
    "    target_encd_dfs.append(target_encd_df)\n",
    "\n",
    "    num_data = df[num_features].reset_index(drop=True)\n",
    "    scaled_num_data = pd.DataFrame(mm_scaler.transform(num_data),\n",
    "                                   columns=num_features)\n",
    "    scaled_target_encd_df = pd.concat(\n",
    "        [target_encd_df.drop(num_features, axis=1), scaled_num_data],\n",
    "        axis=1\n",
    "    )\n",
    "    scaled_target_encd_dfs.append(scaled_target_encd_df)\n",
    "\n",
    "X_train_target, X_train_res_target, X_test_target = target_encd_dfs\n",
    "(X_train_target_scaled,\n",
    " X_train_res_target_scaled,\n",
    " X_test_target_scaled) = scaled_target_encd_dfs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 20)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "train_test_data_dir = \"../data/train_test_data/\"\n",
    "\n",
    "X_train.to_pickle(train_test_data_dir + \"X_train.pkl\")\n",
    "X_train_ohe.to_pickle(train_test_data_dir + \"X_train_ohe.pkl\")\n",
    "X_train_target.to_pickle(train_test_data_dir + \"X_train_target.pkl\")\n",
    "X_train_ohe_scaled.to_pickle(train_test_data_dir + \"X_train_ohe_scaled.pkl\")\n",
    "X_train_target_scaled.to_pickle(train_test_data_dir + \"X_train_target_scaled.pkl\")\n",
    "y_train.to_pickle(train_test_data_dir + \"y_train.pkl\")\n",
    "\n",
    "X_train_res.to_pickle(train_test_data_dir + \"X_train_res.pkl\")\n",
    "X_train_res_ohe.to_pickle(train_test_data_dir + \"X_train_res_ohe.pkl\")\n",
    "X_train_res_target.to_pickle(train_test_data_dir + \"X_train_res_target.pkl\")\n",
    "X_train_res_ohe_scaled.to_pickle(train_test_data_dir + \"X_train_res_ohe_scaled.pkl\")\n",
    "X_train_res_target_scaled.to_pickle(train_test_data_dir + \"X_train_res_target_scaled.pkl\")\n",
    "y_train_res.to_pickle(train_test_data_dir + \"y_train_res.pkl\")\n",
    "\n",
    "X_test.to_pickle(train_test_data_dir + \"X_test.pkl\")\n",
    "X_test_ohe.to_pickle(train_test_data_dir + \"X_test_ohe.pkl\")\n",
    "X_test_target.to_pickle(train_test_data_dir + \"X_test_target.pkl\")\n",
    "X_test_ohe_scaled.to_pickle(train_test_data_dir + \"X_test_ohe_scaled.pkl\")\n",
    "X_test_target_scaled.to_pickle(train_test_data_dir + \"X_test_target_scaled.pkl\")\n",
    "y_test.to_pickle(train_test_data_dir + \"y_test.pkl\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}