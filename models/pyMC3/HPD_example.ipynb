{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "finite-recipient",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/samrelins/Documents/LIDA/ace_project/')\n",
    "\n",
    "from IPython.display import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pymc3 as pm\n",
    "from src.train_test import *\n",
    "from src.data_prep import *\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# load and prep data\n",
    "data_dir = \"/Users/samrelins/Documents/LIDA/ace_project/data/\"\n",
    "data_path = os.path.join(data_dir, \"ace_data_extra.csv\")\n",
    "ace_dat = pd.read_csv(data_path)\n",
    "\n",
    "X_train, y_train, X_test, y_test = return_train_test(ace_dat)\n",
    "X_train, X_test = encode_and_scale(\n",
    "    X_train, y_train, X_test, \n",
    "    cat_encoder=\"one_hot\", \n",
    "    scaled=True\n",
    ")\n",
    "\n",
    "\n",
    "def sample_distribution(X_train, y_train, features):\n",
    "    \"\"\"\n",
    "    Helper function to sample logistic regression bayes model\n",
    "    \n",
    "    :param X_train: (object: pandas DataFrame) input training data dataframe\n",
    "    :param y_train: (object: pandas Series) training labels\n",
    "    :param features: (list) list of features / columns to use \n",
    "        in logistic regression model\n",
    "    \n",
    "    :return: (tuple: (object: pyMC3 Model, object: pyMC3 Trace) \n",
    "        pyMC3 model and trace objects from sampler\n",
    "    \n",
    "    \"\"\"\n",
    "    with pm.Model() as model:\n",
    "        pm.glm.GLM(\n",
    "            x = X_train[features],\n",
    "            y = y_train,\n",
    "            intercept=True,\n",
    "            family=pm.glm.families.Binomial()\n",
    "        )\n",
    "        trace = pm.sample(5000, \n",
    "                          tune=500, \n",
    "                          cores=14,  \n",
    "                          target_accept=0.90,\n",
    "                          init=\"adapt_diag\")\n",
    "    return model, trace\n",
    "        \n",
    "    \n",
    "def return_kde_plot(samples, step=0.001, color=\"red\"):\n",
    "    \"\"\"\n",
    "    returns plolty scatter plot of np.array KDE\n",
    "    \"\"\"\n",
    "    kde = stats.gaussian_kde(samples)\n",
    "    xx = np.arange(samples.min(), samples.max(), step)\n",
    "    yy = kde.evaluate(xx)\n",
    "    kde_plot = go.Scatter(x=xx, \n",
    "                          y=yy, \n",
    "                          line=dict(color=color,\n",
    "                                    shape=\"spline\"),\n",
    "                          mode=\"lines\",\n",
    "                          fill=\"tozeroy\")\n",
    "    return kde_plot\n",
    "        \n",
    "        \n",
    "def return_trace_fig(pymc_trace):\n",
    "    \"\"\"\n",
    "    Helper function to plot trace and KDE plots from pyMC3 samples\n",
    "    \n",
    "    :param pymc_trace: (object: pyMC3 Trace object) input trace\n",
    "    \n",
    "    :return: plotly Figure\n",
    "    \"\"\"\n",
    "    \n",
    "    subplot_titles = []\n",
    "    for title in pymc_trace.varnames:\n",
    "        subplot_titles += [title, \"\"]\n",
    "    fig = make_subplots(rows=len(pymc_trace.varnames), \n",
    "                        cols=2,\n",
    "                        subplot_titles=subplot_titles)\n",
    "\n",
    "    for i, feature in enumerate(pymc_trace.varnames):\n",
    "        samples = pymc_trace[feature]\n",
    "        color = px.colors.qualitative.Plotly[i%10]\n",
    "        \n",
    "        trace_plot = go.Scatter(x=np.arange(len(samples)), \n",
    "                                y=samples,\n",
    "                                line=dict(color=color))\n",
    "        fig.add_trace(trace_plot, row=i+1, col=1)\n",
    "        \n",
    "        kde_plot = return_kde_plot(samples, color=color)\n",
    "        fig.add_trace(kde_plot, row=i+1, col=2)\n",
    "\n",
    "    fig.update_layout(height=200*len(pymc_trace.varnames),\n",
    "                      showlegend=False)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_model, eg_trace = sample_distribution(X_train, y_train, [\"ox_sat\"])\n",
    "trace_fig = return_trace_fig(eg_trace)\n",
    "Image(trace_fig.to_image(format=\"png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mc3env]",
   "language": "python",
   "name": "conda-env-mc3env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
