{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, precision_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "true_neg = make_scorer(lambda y, y_pred: confusion_matrix(y, y_pred)[0][0])\n",
    "false_neg = make_scorer(lambda y, y_pred: confusion_matrix(y, y_pred)[1][0])\n",
    "true_pos = make_scorer(lambda y, y_pred: confusion_matrix(y, y_pred)[1][1])\n",
    "false_pos = make_scorer(lambda y, y_pred: confusion_matrix(y, y_pred)[0][1])\n",
    "precision = make_scorer(precision_score, zero_division=0)\n",
    "\n",
    "SCORING = {\n",
    "    \"roc_auc\":\"roc_auc\",\n",
    "    \"accuracy\":\"accuracy\",\n",
    "    \"recall\": \"recall\",\n",
    "    \"precision\": precision,\n",
    "    \"true_pos\": true_pos,\n",
    "    \"true_neg\": true_neg,\n",
    "    \"false_pos\": false_pos,\n",
    "    \"false_neg\": false_neg\n",
    "}\n",
    "\n",
    "SCORE_FEATURES = [\n",
    "       'mean_test_roc_auc', 'std_test_roc_auc',\n",
    "       'mean_train_roc_auc', 'std_train_roc_auc',\n",
    "       'mean_test_accuracy', 'std_test_accuracy',\n",
    "       'mean_train_accuracy', 'std_train_accuracy',\n",
    "       'mean_test_recall', 'std_test_recall',\n",
    "       'mean_train_recall', 'std_train_recall',\n",
    "       'mean_test_precision', 'std_test_precision',\n",
    "       'mean_train_precision', 'std_train_precision',\n",
    "       'mean_test_true_pos', 'std_test_true_pos',\n",
    "       'mean_train_true_pos', 'std_train_true_pos',\n",
    "       'mean_test_true_neg', 'std_test_true_neg',\n",
    "       'mean_train_true_neg', 'std_train_true_neg',\n",
    "       'mean_test_false_pos', 'std_test_false_pos',\n",
    "       'mean_train_false_pos', 'std_train_false_pos',\n",
    "       'mean_test_false_neg', 'std_test_false_neg',\n",
    "       'mean_train_false_neg', 'std_train_false_neg'\n",
    "]\n",
    "\n",
    "def test_model(clf, X, y, param_grid, **kwargs):\n",
    "    search_fit = GridSearchCV(clf,\n",
    "                              param_grid,\n",
    "                              scoring=SCORING,\n",
    "                              refit=\"roc_auc\",\n",
    "                              return_train_score=True).fit(X, y, **kwargs)\n",
    "    search_results = pd.DataFrame(search_fit.cv_results_)[SCORE_FEATURES]\n",
    "    return search_fit.best_params_, search_results.iloc[search_fit.best_index_]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def nns(X, y, balanced=False):\n",
    "    clf = KNeighborsClassifier(n_jobs=-2)\n",
    "    param_grid = {'n_neighbors': np.arange(1,10),\n",
    "                    'weights': ['uniform','distance'],\n",
    "                    'metric':['euclidean','manhattan']}\n",
    "    return test_model(clf, X, y, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def svm(X, y, balanced=False):\n",
    "    clf = SVC()\n",
    "    param_grid = {'kernel': ['linear','rbf'],\n",
    "                  'C': np.logspace(2,4,2), # np.logspace(2,5,6)\n",
    "                  'gamma': np.logspace(-4,0.5,1)} # np.logspace(-4,0.5,10)}\n",
    "    if balanced:\n",
    "        param_grid[\"class_weight\"] = [\"balanced\"],\n",
    "    return test_model(clf, X, y, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "def gp(X, y, balanced=False):\n",
    "    clf = GaussianProcessClassifier(random_state=0, n_jobs=-2)\n",
    "    param_grid = {'kernel': [1.0 * RBF(1.0)]}\n",
    "    return test_model(clf, X, y, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def rfc(X, y, balanced=False):\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    param_grid = {'max_depth': [4, 6],\n",
    "                  'min_samples_leaf': [3,5,9,17],\n",
    "                  'max_features': [0.3]}\n",
    "    if balanced:\n",
    "        param_grid[\"class_weight\"] = [\"balanced\"],\n",
    "    return test_model(clf, X, y, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def gbc(X, y, balanced=False):\n",
    "    clf = GradientBoostingClassifier(n_estimators=100,random_state=0)\n",
    "    param_grid = {'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "                    'max_depth': [3,4,6],\n",
    "                    'min_samples_leaf': [3,5,9,17],\n",
    "                    'max_features': [x for x in np.linspace(0.2,0.4,4)]}\n",
    "    if balanced:\n",
    "        pos_weight, neg_weight = compute_class_weight(class_weight=\"balanced\",\n",
    "                                                      classes=[1,0],\n",
    "                                                      y=y)\n",
    "        y_weights = y.apply(lambda y: pos_weight if y else neg_weight)\n",
    "    else:\n",
    "        y_weights = np.ones(y.shape)\n",
    "\n",
    "    return test_model(clf, X, y, param_grid, sample_weight=y_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "({'learning_rate': 0.1,\n  'max_depth': 4,\n  'max_features': 0.26666666666666666,\n  'min_samples_leaf': 3},\n mean_test_roc_auc         0.603783\n std_test_roc_auc          0.093483\n mean_train_roc_auc        1.000000\n std_train_roc_auc         0.000000\n mean_test_accuracy        0.808696\n std_test_accuracy         0.024934\n mean_train_accuracy       0.994203\n std_train_accuracy        0.003695\n mean_test_recall          0.101515\n std_test_recall           0.081396\n mean_train_recall         0.966223\n std_train_recall          0.021336\n mean_test_precision       0.326667\n std_test_precision        0.213333\n mean_train_precision      1.000000\n std_train_precision       0.000000\n mean_test_true_pos        1.200000\n std_test_true_pos         0.979796\n mean_train_true_pos      45.600000\n std_train_true_pos        0.800000\n mean_test_true_neg       54.600000\n std_test_true_neg         1.019804\n mean_train_true_neg     228.800000\n std_train_true_neg        0.400000\n mean_test_false_pos       2.600000\n std_test_false_pos        1.200000\n mean_train_false_pos      0.000000\n std_train_false_pos       0.000000\n mean_test_false_neg      10.600000\n std_test_false_neg        1.019804\n mean_train_false_neg      1.600000\n std_train_false_neg       1.019804\n Name: 20, dtype: float64)"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc(X_train_ohe, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "({'learning_rate': 0.05,\n  'max_depth': 4,\n  'max_features': 0.4,\n  'min_samples_leaf': 17},\n mean_test_roc_auc         0.589000\n std_test_roc_auc          0.082245\n mean_train_roc_auc        0.987245\n std_train_roc_auc         0.003002\n mean_test_accuracy        0.724638\n std_test_accuracy         0.035500\n mean_train_accuracy       0.924638\n std_train_accuracy        0.007390\n mean_test_recall          0.322727\n std_test_recall           0.144584\n mean_train_recall         1.000000\n std_train_recall          0.000000\n mean_test_precision       0.247165\n std_test_precision        0.088026\n mean_train_precision      0.694706\n std_train_precision       0.021783\n mean_test_true_pos        3.800000\n std_test_true_pos         1.720465\n mean_train_true_pos      47.200000\n std_train_true_pos        0.400000\n mean_test_true_neg       46.200000\n std_test_true_neg         2.785678\n mean_train_true_neg     208.000000\n std_train_true_neg        1.897367\n mean_test_false_pos      11.000000\n std_test_false_pos        2.828427\n mean_train_false_pos     20.800000\n std_train_false_pos       2.039608\n mean_test_false_neg       8.000000\n std_test_false_neg        1.788854\n mean_train_false_neg      0.000000\n std_train_false_neg       0.000000\n Name: 79, dtype: float64)"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc(X_train_ohe, y_train, balanced=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def ab(X, y, balanced=False):\n",
    "    clf = AdaBoostClassifier(random_state=0)\n",
    "    param_grid = {'n_estimators': [100,200],\n",
    "                  'learning_rate': [0.001,0.01,0.1,0.2,0.5]}\n",
    "    if balanced:\n",
    "        pos_weight, neg_weight = compute_class_weight(class_weight=\"balanced\",\n",
    "                                                      classes=[1,0],\n",
    "                                                      y=y)\n",
    "        y_weights = y.apply(lambda y: pos_weight if y else neg_weight)\n",
    "    else:\n",
    "        y_weights = np.ones(y.shape)\n",
    "\n",
    "    return test_model(clf, X, y, param_grid, sample_weight=y_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "({'learning_rate': 0.2, 'n_estimators': 200},\n mean_test_roc_auc         0.590280\n std_test_roc_auc          0.106138\n mean_train_roc_auc        0.947166\n std_train_roc_auc         0.013459\n mean_test_accuracy        0.814493\n std_test_accuracy         0.042402\n mean_train_accuracy       0.874638\n std_train_accuracy        0.013672\n mean_test_recall          0.101515\n std_test_recall           0.081396\n mean_train_recall         0.326064\n std_train_recall          0.072066\n mean_test_precision       0.500000\n std_test_precision        0.353553\n mean_train_precision      0.842628\n std_train_precision       0.076936\n mean_test_true_pos        1.200000\n std_test_true_pos         0.979796\n mean_train_true_pos      15.400000\n std_train_true_pos        3.440930\n mean_test_true_neg       55.000000\n std_test_true_neg         2.280351\n mean_train_true_neg     226.000000\n std_train_true_neg        1.264911\n mean_test_false_pos       2.200000\n std_test_false_pos        2.135416\n mean_train_false_pos      2.800000\n std_train_false_pos       1.326650\n mean_test_false_neg      10.600000\n std_test_false_neg        1.019804\n mean_train_false_neg     31.800000\n std_train_false_neg       3.310589\n Name: 7, dtype: float64)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab(X_train_ohe, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "({'learning_rate': 0.1, 'n_estimators': 200},\n mean_test_roc_auc         0.587900\n std_test_roc_auc          0.092174\n mean_train_roc_auc        0.917463\n std_train_roc_auc         0.017252\n mean_test_accuracy        0.689855\n std_test_accuracy         0.045462\n mean_train_accuracy       0.802899\n std_train_accuracy        0.017240\n mean_test_recall          0.425758\n std_test_recall           0.187561\n mean_train_recall         0.868528\n std_train_recall          0.041540\n mean_test_precision       0.248419\n std_test_precision        0.085682\n mean_train_precision      0.460335\n std_train_precision       0.026577\n mean_test_true_pos        5.000000\n std_test_true_pos         2.190890\n mean_train_true_pos      41.000000\n std_train_true_pos        2.097618\n mean_test_true_neg       42.600000\n std_test_true_neg         3.072458\n mean_train_true_neg     180.600000\n std_train_true_neg        4.127953\n mean_test_false_pos      14.600000\n std_test_false_pos        3.006659\n mean_train_false_pos     48.200000\n std_train_false_pos       4.166533\n mean_test_false_neg       6.800000\n std_test_false_neg        2.315167\n mean_train_false_neg      6.200000\n std_train_false_neg       1.939072\n Name: 5, dtype: float64)"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab(X_train_ohe, y_train, balanced=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def nb(X, y, balanced=False):\n",
    "    clf = GaussianNB()\n",
    "    param_grid = {'var_smoothing':  np.logspace(-11,-3,9,base=10)}\n",
    "    if balanced:\n",
    "        pos_weight, neg_weight = compute_class_weight(class_weight=\"balanced\",\n",
    "                                                      classes=[1,0],\n",
    "                                                      y=y)\n",
    "        y_weights = y.apply(lambda y: pos_weight if y else neg_weight)\n",
    "    else:\n",
    "        y_weights = np.ones(y.shape)\n",
    "    return test_model(clf, X, y, param_grid, sample_weight=y_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "({'var_smoothing': 0.001},\n mean_test_roc_auc         0.533499\n std_test_roc_auc          0.072551\n mean_train_roc_auc        0.718361\n std_train_roc_auc         0.016121\n mean_test_accuracy        0.797101\n std_test_accuracy         0.022452\n mean_train_accuracy       0.830435\n std_train_accuracy        0.009559\n mean_test_recall          0.083333\n std_test_recall           0.091287\n mean_train_recall         0.182358\n std_train_recall          0.044308\n mean_test_precision       0.219048\n std_test_precision        0.182201\n mean_train_precision      0.519149\n std_train_precision       0.077738\n mean_test_true_pos        1.000000\n std_test_true_pos         1.095445\n mean_train_true_pos       8.600000\n std_train_true_pos        2.059126\n mean_test_true_neg       54.000000\n std_test_true_neg         1.264911\n mean_train_true_neg     220.600000\n std_train_true_neg        2.653300\n mean_test_false_pos       3.200000\n std_test_false_pos        1.600000\n mean_train_false_pos      8.200000\n std_train_false_pos       2.481935\n mean_test_false_neg      10.800000\n std_test_false_neg        0.979796\n mean_train_false_neg     38.600000\n std_train_false_neg       2.244994\n Name: 8, dtype: float64)"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb(X_train_ohe, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "({'var_smoothing': 0.001},\n mean_test_roc_auc         0.533499\n std_test_roc_auc          0.072551\n mean_train_roc_auc        0.718361\n std_train_roc_auc         0.016121\n mean_test_accuracy        0.684058\n std_test_accuracy         0.059685\n mean_train_accuracy       0.734058\n std_train_accuracy        0.050079\n mean_test_recall          0.337879\n std_test_recall           0.102158\n mean_train_recall         0.551152\n std_train_recall          0.088782\n mean_test_precision       0.230590\n std_test_precision        0.046357\n mean_train_precision      0.341162\n std_train_precision       0.031857\n mean_test_true_pos        4.000000\n std_test_true_pos         1.264911\n mean_train_true_pos      26.000000\n std_train_true_pos        4.098780\n mean_test_true_neg       43.200000\n std_test_true_neg         5.114685\n mean_train_true_neg     176.600000\n std_train_true_neg       17.816846\n mean_test_false_pos      14.000000\n std_test_false_pos        5.176872\n mean_train_false_pos     52.200000\n std_train_false_pos      17.926517\n mean_test_false_neg       7.800000\n std_test_false_neg        1.166190\n mean_train_false_neg     21.200000\n std_train_false_neg       4.261455\n Name: 8, dtype: float64)"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb(X_train_ohe, y_train, balanced=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def lr(X, y, balanced=False):\n",
    "    clf = LogisticRegression(random_state=0, max_iter=10000)\n",
    "    param_grid = {'penalty' : ['l2'],\n",
    "                  'solver': [\"liblinear\"],\n",
    "                  'C' : np.logspace(-4, 4, 20)}\n",
    "    if balanced:\n",
    "        param_grid[\"class_weight\"] = [\"balanced\"],\n",
    "    return test_model(clf, X, y, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "def qda(X, y):\n",
    "    clf = QuadraticDiscriminantAnalysis()\n",
    "    param_grid = {'reg_param':  [0.0]}\n",
    "    return test_model(clf, X, y, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def lda(X, y):\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    param_grid = {'solver':  [\"svd\", \"lsqr\", \"eigen\"],\n",
    "                  \"shrinkage\": [None, \"auto\", 0.1, 0.3, 0.8, 1]}\n",
    "    return test_model(clf, X, y, param_grid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "({'shrinkage': 0.3, 'solver': 'lsqr'},\n mean_test_roc_auc         0.547332\n std_test_roc_auc          0.080731\n mean_train_roc_auc        0.666632\n std_train_roc_auc         0.020374\n mean_test_accuracy        0.828986\n std_test_accuracy         0.005797\n mean_train_accuracy       0.834783\n std_train_accuracy        0.002899\n mean_test_recall          0.016667\n std_test_recall           0.033333\n mean_train_recall         0.046454\n std_train_recall          0.033649\n mean_test_precision       0.200000\n std_test_precision        0.400000\n mean_train_precision      0.693333\n std_train_precision       0.369023\n mean_test_true_pos        0.200000\n std_test_true_pos         0.400000\n mean_train_true_pos       2.200000\n std_train_true_pos        1.600000\n mean_test_true_neg       57.000000\n std_test_true_neg         0.000000\n mean_train_true_neg     228.200000\n std_train_true_neg        0.979796\n mean_test_false_pos       0.200000\n std_test_false_pos        0.400000\n mean_train_false_pos      0.600000\n std_train_false_pos       0.800000\n mean_test_false_neg      11.600000\n std_test_false_neg        0.489898\n mean_train_false_neg     45.000000\n std_train_false_neg       1.414214\n Name: 10, dtype: float64)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda(X_train_ohe, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting K Nearest Neighbours......\n",
      "done.\n",
      "fitting Support Vector Machines......\n",
      "done.\n",
      "fitting Gaussian Process......\n",
      "done.\n",
      "fitting Random Forest Classifier......\n",
      "done.\n",
      "fitting Gradient Boosting Classifier......\n",
      "done.\n",
      "fitting Ada Boost classifier......\n",
      "done.\n",
      "fitting Gaussian Naieve Bayes......\n",
      "done.\n",
      "fitting Logistic Regression......\n",
      "done.\n",
      "fitting Quadratic Discriminant Analysis......\n",
      "done.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                 mean_test_accuracy  std_test_accuracy  \\\nK Nearest Neighbours                       0.834783           0.011594   \nSupport Vector Machines                    0.828986           0.005797   \nGaussian Process                           0.828986           0.005797   \nRandom Forest Classifier                   0.828986           0.005797   \nGradient Boosting Classifier               0.831884           0.007100   \nAda Boost classifier                       0.828986           0.005797   \nGaussian Naieve Bayes                      0.797101           0.022452   \nLogistic Regression                        0.828986           0.005797   \nQuadratic Discriminant Analysis            0.817391           0.011594   \n\n                                 mean_train_accuracy  std_train_accuracy  \\\nK Nearest Neighbours                        1.000000            0.000000   \nSupport Vector Machines                     0.828986            0.001449   \nGaussian Process                            0.828986            0.001449   \nRandom Forest Classifier                    0.832609            0.004225   \nGradient Boosting Classifier                0.863768            0.005423   \nAda Boost classifier                        0.831884            0.002899   \nGaussian Naieve Bayes                       0.830435            0.009559   \nLogistic Regression                         0.828986            0.001449   \nQuadratic Discriminant Analysis             0.841304            0.014200   \n\n                                 mean_test_recall  std_test_recall  \\\nK Nearest Neighbours                     0.034848         0.042748   \nSupport Vector Machines                  0.000000         0.000000   \nGaussian Process                         0.000000         0.000000   \nRandom Forest Classifier                 0.000000         0.000000   \nGradient Boosting Classifier             0.033333         0.040825   \nAda Boost classifier                     0.000000         0.000000   \nGaussian Naieve Bayes                    0.083333         0.091287   \nLogistic Regression                      0.000000         0.000000   \nQuadratic Discriminant Analysis          0.016667         0.033333   \n\n                                 mean_train_recall  std_train_recall  \\\nK Nearest Neighbours                      1.000000          0.000000   \nSupport Vector Machines                   0.000000          0.000000   \nGaussian Process                          0.000000          0.000000   \nRandom Forest Classifier                  0.021099          0.026775   \nGradient Boosting Classifier              0.203457          0.029255   \nAda Boost classifier                      0.016933          0.015899   \nGaussian Naieve Bayes                     0.182358          0.044308   \nLogistic Regression                       0.000000          0.000000   \nQuadratic Discriminant Analysis           0.071277          0.089741   \n\n                                 mean_test_precision  std_test_precision  ...  \\\nK Nearest Neighbours                        0.400000            0.489898  ...   \nSupport Vector Machines                     0.000000            0.000000  ...   \nGaussian Process                            0.000000            0.000000  ...   \nRandom Forest Classifier                    0.000000            0.000000  ...   \nGradient Boosting Classifier                0.400000            0.489898  ...   \nAda Boost classifier                        0.000000            0.000000  ...   \nGaussian Naieve Bayes                       0.219048            0.182201  ...   \nLogistic Regression                         0.000000            0.000000  ...   \nQuadratic Discriminant Analysis             0.066667            0.133333  ...   \n\n                                 mean_train_true_neg  std_train_true_neg  \\\nK Nearest Neighbours                           228.8              0.4000   \nSupport Vector Machines                        228.8              0.4000   \nGaussian Process                               228.8              0.4000   \nRandom Forest Classifier                       228.8              0.4000   \nGradient Boosting Classifier                   228.8              0.4000   \nAda Boost classifier                           228.8              0.4000   \nGaussian Naieve Bayes                          220.6              2.6533   \nLogistic Regression                            228.8              0.4000   \nQuadratic Discriminant Analysis                228.8              0.4000   \n\n                                 mean_test_false_pos  std_test_false_pos  \\\nK Nearest Neighbours                             0.0            0.000000   \nSupport Vector Machines                          0.0            0.000000   \nGaussian Process                                 0.0            0.000000   \nRandom Forest Classifier                         0.0            0.000000   \nGradient Boosting Classifier                     0.2            0.400000   \nAda Boost classifier                             0.0            0.000000   \nGaussian Naieve Bayes                            3.2            1.600000   \nLogistic Regression                              0.0            0.000000   \nQuadratic Discriminant Analysis                  1.0            0.894427   \n\n                                 mean_train_false_pos  std_train_false_pos  \\\nK Nearest Neighbours                              0.0             0.000000   \nSupport Vector Machines                           0.0             0.000000   \nGaussian Process                                  0.0             0.000000   \nRandom Forest Classifier                          0.0             0.000000   \nGradient Boosting Classifier                      0.0             0.000000   \nAda Boost classifier                              0.0             0.000000   \nGaussian Naieve Bayes                             8.2             2.481935   \nLogistic Regression                               0.0             0.000000   \nQuadratic Discriminant Analysis                   0.0             0.000000   \n\n                                 mean_test_false_neg  std_test_false_neg  \\\nK Nearest Neighbours                            11.4            0.800000   \nSupport Vector Machines                         11.8            0.400000   \nGaussian Process                                11.8            0.400000   \nRandom Forest Classifier                        11.8            0.400000   \nGradient Boosting Classifier                    11.4            0.489898   \nAda Boost classifier                            11.8            0.400000   \nGaussian Naieve Bayes                           10.8            0.979796   \nLogistic Regression                             11.8            0.400000   \nQuadratic Discriminant Analysis                 11.6            0.489898   \n\n                                 mean_train_false_neg  std_train_false_neg  \nK Nearest Neighbours                              0.0             0.000000  \nSupport Vector Machines                          47.2             0.400000  \nGaussian Process                                 47.2             0.400000  \nRandom Forest Classifier                         46.2             1.166190  \nGradient Boosting Classifier                     37.6             1.496663  \nAda Boost classifier                             46.4             0.800000  \nGaussian Naieve Bayes                            38.6             2.244994  \nLogistic Regression                              47.2             0.400000  \nQuadratic Discriminant Analysis                  43.8             3.919184  \n\n[9 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_test_accuracy</th>\n      <th>std_test_accuracy</th>\n      <th>mean_train_accuracy</th>\n      <th>std_train_accuracy</th>\n      <th>mean_test_recall</th>\n      <th>std_test_recall</th>\n      <th>mean_train_recall</th>\n      <th>std_train_recall</th>\n      <th>mean_test_precision</th>\n      <th>std_test_precision</th>\n      <th>...</th>\n      <th>mean_train_true_neg</th>\n      <th>std_train_true_neg</th>\n      <th>mean_test_false_pos</th>\n      <th>std_test_false_pos</th>\n      <th>mean_train_false_pos</th>\n      <th>std_train_false_pos</th>\n      <th>mean_test_false_neg</th>\n      <th>std_test_false_neg</th>\n      <th>mean_train_false_neg</th>\n      <th>std_train_false_neg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>K Nearest Neighbours</th>\n      <td>0.834783</td>\n      <td>0.011594</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.034848</td>\n      <td>0.042748</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.400000</td>\n      <td>0.489898</td>\n      <td>...</td>\n      <td>228.8</td>\n      <td>0.4000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.4</td>\n      <td>0.800000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Support Vector Machines</th>\n      <td>0.828986</td>\n      <td>0.005797</td>\n      <td>0.828986</td>\n      <td>0.001449</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>228.8</td>\n      <td>0.4000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.8</td>\n      <td>0.400000</td>\n      <td>47.2</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>Gaussian Process</th>\n      <td>0.828986</td>\n      <td>0.005797</td>\n      <td>0.828986</td>\n      <td>0.001449</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>228.8</td>\n      <td>0.4000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.8</td>\n      <td>0.400000</td>\n      <td>47.2</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>Random Forest Classifier</th>\n      <td>0.828986</td>\n      <td>0.005797</td>\n      <td>0.832609</td>\n      <td>0.004225</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.021099</td>\n      <td>0.026775</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>228.8</td>\n      <td>0.4000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.8</td>\n      <td>0.400000</td>\n      <td>46.2</td>\n      <td>1.166190</td>\n    </tr>\n    <tr>\n      <th>Gradient Boosting Classifier</th>\n      <td>0.831884</td>\n      <td>0.007100</td>\n      <td>0.863768</td>\n      <td>0.005423</td>\n      <td>0.033333</td>\n      <td>0.040825</td>\n      <td>0.203457</td>\n      <td>0.029255</td>\n      <td>0.400000</td>\n      <td>0.489898</td>\n      <td>...</td>\n      <td>228.8</td>\n      <td>0.4000</td>\n      <td>0.2</td>\n      <td>0.400000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.4</td>\n      <td>0.489898</td>\n      <td>37.6</td>\n      <td>1.496663</td>\n    </tr>\n    <tr>\n      <th>Ada Boost classifier</th>\n      <td>0.828986</td>\n      <td>0.005797</td>\n      <td>0.831884</td>\n      <td>0.002899</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.016933</td>\n      <td>0.015899</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>228.8</td>\n      <td>0.4000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.8</td>\n      <td>0.400000</td>\n      <td>46.4</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <th>Gaussian Naieve Bayes</th>\n      <td>0.797101</td>\n      <td>0.022452</td>\n      <td>0.830435</td>\n      <td>0.009559</td>\n      <td>0.083333</td>\n      <td>0.091287</td>\n      <td>0.182358</td>\n      <td>0.044308</td>\n      <td>0.219048</td>\n      <td>0.182201</td>\n      <td>...</td>\n      <td>220.6</td>\n      <td>2.6533</td>\n      <td>3.2</td>\n      <td>1.600000</td>\n      <td>8.2</td>\n      <td>2.481935</td>\n      <td>10.8</td>\n      <td>0.979796</td>\n      <td>38.6</td>\n      <td>2.244994</td>\n    </tr>\n    <tr>\n      <th>Logistic Regression</th>\n      <td>0.828986</td>\n      <td>0.005797</td>\n      <td>0.828986</td>\n      <td>0.001449</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>228.8</td>\n      <td>0.4000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.8</td>\n      <td>0.400000</td>\n      <td>47.2</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>Quadratic Discriminant Analysis</th>\n      <td>0.817391</td>\n      <td>0.011594</td>\n      <td>0.841304</td>\n      <td>0.014200</td>\n      <td>0.016667</td>\n      <td>0.033333</td>\n      <td>0.071277</td>\n      <td>0.089741</td>\n      <td>0.066667</td>\n      <td>0.133333</td>\n      <td>...</td>\n      <td>228.8</td>\n      <td>0.4000</td>\n      <td>1.0</td>\n      <td>0.894427</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.6</td>\n      <td>0.489898</td>\n      <td>43.8</td>\n      <td>3.919184</td>\n    </tr>\n  </tbody>\n</table>\n<p>9 rows Ã— 28 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"../data/train_test_data/\"\n",
    "\n",
    "X_train_ohe = pd.read_pickle(data_dir + \"X_train_ohe.pkl\")\n",
    "X_train_ohe_scaled = pd.read_pickle(data_dir + \"X_train_ohe_scaled.pkl\")\n",
    "y_train = pd.read_pickle(data_dir + \"y_train.pkl\")\n",
    "\n",
    "techniques_dict = {'K Nearest Neighbours': nns, 'Support Vector Machines': svm,\n",
    "                   'Gaussian Process': gp, 'Random Forest Classifier': rfc,\n",
    "                   'Gradient Boosting Classifier': gbc,  'Ada Boost classifier': ab,\n",
    "                   'Gaussian Naieve Bayes': nb, 'Logistic Regression': lr,\n",
    "                   \"Linear Discriminant Analysis\": lda,\n",
    "                   'Quadratic Discriminant Analysis': qda}\n",
    "\n",
    "cv_results_list = []\n",
    "best_params_dict = {}\n",
    "for model_type, cv_model_func in techniques_dict.items():\n",
    "    print(f\"fitting {model_type}......\")\n",
    "    if cv_model_func in [nns, svm, gp, lr, lda, qda]:\n",
    "        best_params, cv_results = cv_model_func(X_train_ohe_scaled, y_train)\n",
    "        best_params_dict[model_type] = best_params\n",
    "        cv_results_list.append(cv_results)\n",
    "    else: # don't normalise x\n",
    "        best_params, cv_results = cv_model_func(X_train_ohe, y_train)\n",
    "        best_params_dict[model_type] = best_params\n",
    "        cv_results_list.append(cv_results)\n",
    "    print(\"done.\")\n",
    "\n",
    "cv_results_df = pd.DataFrame(cv_results_list,\n",
    "                             index=techniques_dict.keys())\n",
    "cv_results_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 mean_train_accuracy  mean_test_accuracy  \\\nK Nearest Neighbours                        1.000000            0.834783   \nSupport Vector Machines                     0.828986            0.828986   \nGaussian Process                            0.828986            0.828986   \nRandom Forest Classifier                    0.832609            0.828986   \nGradient Boosting Classifier                0.863768            0.831884   \nAda Boost classifier                        0.831884            0.828986   \nGaussian Naieve Bayes                       0.830435            0.797101   \nLogistic Regression                         0.828986            0.828986   \nQuadratic Discriminant Analysis             0.841304            0.817391   \n\n                                 mean_train_precision  mean_train_recall  \\\nK Nearest Neighbours                         1.000000           1.000000   \nSupport Vector Machines                      0.000000           0.000000   \nGaussian Process                             0.000000           0.000000   \nRandom Forest Classifier                     0.400000           0.021099   \nGradient Boosting Classifier                 1.000000           0.203457   \nAda Boost classifier                         0.600000           0.016933   \nGaussian Naieve Bayes                        0.519149           0.182358   \nLogistic Regression                          0.000000           0.000000   \nQuadratic Discriminant Analysis              1.000000           0.071277   \n\n                                 mean_test_precision  mean_test_recall  \\\nK Nearest Neighbours                        0.400000          0.034848   \nSupport Vector Machines                     0.000000          0.000000   \nGaussian Process                            0.000000          0.000000   \nRandom Forest Classifier                    0.000000          0.000000   \nGradient Boosting Classifier                0.400000          0.033333   \nAda Boost classifier                        0.000000          0.000000   \nGaussian Naieve Bayes                       0.219048          0.083333   \nLogistic Regression                         0.000000          0.000000   \nQuadratic Discriminant Analysis             0.066667          0.016667   \n\n                                 mean_test_true_neg  mean_test_false_neg  \\\nK Nearest Neighbours                           57.2                 11.4   \nSupport Vector Machines                        57.2                 11.8   \nGaussian Process                               57.2                 11.8   \nRandom Forest Classifier                       57.2                 11.8   \nGradient Boosting Classifier                   57.0                 11.4   \nAda Boost classifier                           57.2                 11.8   \nGaussian Naieve Bayes                          54.0                 10.8   \nLogistic Regression                            57.2                 11.8   \nQuadratic Discriminant Analysis                56.2                 11.6   \n\n                                 mean_test_true_pos  mean_test_false_pos  \nK Nearest Neighbours                            0.4                  0.0  \nSupport Vector Machines                         0.0                  0.0  \nGaussian Process                                0.0                  0.0  \nRandom Forest Classifier                        0.0                  0.0  \nGradient Boosting Classifier                    0.4                  0.2  \nAda Boost classifier                            0.0                  0.0  \nGaussian Naieve Bayes                           1.0                  3.2  \nLogistic Regression                             0.0                  0.0  \nQuadratic Discriminant Analysis                 0.2                  1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_train_accuracy</th>\n      <th>mean_test_accuracy</th>\n      <th>mean_train_precision</th>\n      <th>mean_train_recall</th>\n      <th>mean_test_precision</th>\n      <th>mean_test_recall</th>\n      <th>mean_test_true_neg</th>\n      <th>mean_test_false_neg</th>\n      <th>mean_test_true_pos</th>\n      <th>mean_test_false_pos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>K Nearest Neighbours</th>\n      <td>1.000000</td>\n      <td>0.834783</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.400000</td>\n      <td>0.034848</td>\n      <td>57.2</td>\n      <td>11.4</td>\n      <td>0.4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Support Vector Machines</th>\n      <td>0.828986</td>\n      <td>0.828986</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>57.2</td>\n      <td>11.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Gaussian Process</th>\n      <td>0.828986</td>\n      <td>0.828986</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>57.2</td>\n      <td>11.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Random Forest Classifier</th>\n      <td>0.832609</td>\n      <td>0.828986</td>\n      <td>0.400000</td>\n      <td>0.021099</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>57.2</td>\n      <td>11.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Gradient Boosting Classifier</th>\n      <td>0.863768</td>\n      <td>0.831884</td>\n      <td>1.000000</td>\n      <td>0.203457</td>\n      <td>0.400000</td>\n      <td>0.033333</td>\n      <td>57.0</td>\n      <td>11.4</td>\n      <td>0.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>Ada Boost classifier</th>\n      <td>0.831884</td>\n      <td>0.828986</td>\n      <td>0.600000</td>\n      <td>0.016933</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>57.2</td>\n      <td>11.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Gaussian Naieve Bayes</th>\n      <td>0.830435</td>\n      <td>0.797101</td>\n      <td>0.519149</td>\n      <td>0.182358</td>\n      <td>0.219048</td>\n      <td>0.083333</td>\n      <td>54.0</td>\n      <td>10.8</td>\n      <td>1.0</td>\n      <td>3.2</td>\n    </tr>\n    <tr>\n      <th>Logistic Regression</th>\n      <td>0.828986</td>\n      <td>0.828986</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>57.2</td>\n      <td>11.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Quadratic Discriminant Analysis</th>\n      <td>0.841304</td>\n      <td>0.817391</td>\n      <td>1.000000</td>\n      <td>0.071277</td>\n      <td>0.066667</td>\n      <td>0.016667</td>\n      <td>56.2</td>\n      <td>11.6</td>\n      <td>0.2</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_features = [\n",
    "    \"mean_train_accuracy\", \"mean_test_accuracy\",\n",
    "    \"mean_train_precision\", \"mean_train_recall\",\n",
    "    \"mean_test_precision\", \"mean_test_recall\",\n",
    "    \"mean_test_true_neg\", \"mean_test_false_neg\",\n",
    "    \"mean_test_true_pos\", \"mean_test_false_pos\",\n",
    "]\n",
    "\n",
    "cv_results_df[display_features]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting K Nearest Neighbours......\n",
      "done.\n",
      "fitting Support Vector Machines......\n",
      "done.\n",
      "fitting Gaussian Process......\n",
      "done.\n",
      "fitting Random Forest Classifier......\n",
      "done.\n",
      "fitting Gradient Boosting Classifier......\n",
      "done.\n",
      "fitting Ada Boost classifier......\n",
      "done.\n",
      "fitting Gaussian Naieve Bayes......\n",
      "done.\n",
      "fitting Logistic Regression......\n",
      "done.\n",
      "fitting Quadratic Discriminant Analysis......\n",
      "done.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                 mean_test_accuracy  std_test_accuracy  \\\nK Nearest Neighbours                       0.834783           0.011594   \nSupport Vector Machines                    0.828986           0.005797   \nGaussian Process                           0.828986           0.005797   \nRandom Forest Classifier                   0.828986           0.005797   \nGradient Boosting Classifier               0.831884           0.007100   \nAda Boost classifier                       0.828986           0.005797   \nGaussian Naieve Bayes                      0.797101           0.022452   \nLogistic Regression                        0.828986           0.005797   \nQuadratic Discriminant Analysis            0.817391           0.011594   \n\n                                 mean_train_accuracy  std_train_accuracy  \\\nK Nearest Neighbours                        1.000000            0.000000   \nSupport Vector Machines                     0.828986            0.001449   \nGaussian Process                            0.828986            0.001449   \nRandom Forest Classifier                    0.832609            0.004225   \nGradient Boosting Classifier                0.863768            0.005423   \nAda Boost classifier                        0.831884            0.002899   \nGaussian Naieve Bayes                       0.830435            0.009559   \nLogistic Regression                         0.828986            0.001449   \nQuadratic Discriminant Analysis             0.841304            0.014200   \n\n                                 mean_test_recall  std_test_recall  \\\nK Nearest Neighbours                     0.034848         0.042748   \nSupport Vector Machines                  0.000000         0.000000   \nGaussian Process                         0.000000         0.000000   \nRandom Forest Classifier                 0.000000         0.000000   \nGradient Boosting Classifier             0.033333         0.040825   \nAda Boost classifier                     0.000000         0.000000   \nGaussian Naieve Bayes                    0.083333         0.091287   \nLogistic Regression                      0.000000         0.000000   \nQuadratic Discriminant Analysis          0.016667         0.033333   \n\n                                 mean_train_recall  std_train_recall  \\\nK Nearest Neighbours                      1.000000          0.000000   \nSupport Vector Machines                   0.000000          0.000000   \nGaussian Process                          0.000000          0.000000   \nRandom Forest Classifier                  0.021099          0.026775   \nGradient Boosting Classifier              0.203457          0.029255   \nAda Boost classifier                      0.016933          0.015899   \nGaussian Naieve Bayes                     0.182358          0.044308   \nLogistic Regression                       0.000000          0.000000   \nQuadratic Discriminant Analysis           0.071277          0.089741   \n\n                                 mean_test_precision  std_test_precision  ...  \\\nK Nearest Neighbours                        0.400000            0.489898  ...   \nSupport Vector Machines                     0.000000            0.000000  ...   \nGaussian Process                            0.000000            0.000000  ...   \nRandom Forest Classifier                    0.000000            0.000000  ...   \nGradient Boosting Classifier                0.400000            0.489898  ...   \nAda Boost classifier                        0.000000            0.000000  ...   \nGaussian Naieve Bayes                       0.219048            0.182201  ...   \nLogistic Regression                         0.000000            0.000000  ...   \nQuadratic Discriminant Analysis             0.066667            0.133333  ...   \n\n                                 mean_train_true_neg  std_train_true_neg  \\\nK Nearest Neighbours                           228.8              0.4000   \nSupport Vector Machines                        228.8              0.4000   \nGaussian Process                               228.8              0.4000   \nRandom Forest Classifier                       228.8              0.4000   \nGradient Boosting Classifier                   228.8              0.4000   \nAda Boost classifier                           228.8              0.4000   \nGaussian Naieve Bayes                          220.6              2.6533   \nLogistic Regression                            228.8              0.4000   \nQuadratic Discriminant Analysis                228.8              0.4000   \n\n                                 mean_test_false_pos  std_test_false_pos  \\\nK Nearest Neighbours                             0.0            0.000000   \nSupport Vector Machines                          0.0            0.000000   \nGaussian Process                                 0.0            0.000000   \nRandom Forest Classifier                         0.0            0.000000   \nGradient Boosting Classifier                     0.2            0.400000   \nAda Boost classifier                             0.0            0.000000   \nGaussian Naieve Bayes                            3.2            1.600000   \nLogistic Regression                              0.0            0.000000   \nQuadratic Discriminant Analysis                  1.0            0.894427   \n\n                                 mean_train_false_pos  std_train_false_pos  \\\nK Nearest Neighbours                              0.0             0.000000   \nSupport Vector Machines                           0.0             0.000000   \nGaussian Process                                  0.0             0.000000   \nRandom Forest Classifier                          0.0             0.000000   \nGradient Boosting Classifier                      0.0             0.000000   \nAda Boost classifier                              0.0             0.000000   \nGaussian Naieve Bayes                             8.2             2.481935   \nLogistic Regression                               0.0             0.000000   \nQuadratic Discriminant Analysis                   0.0             0.000000   \n\n                                 mean_test_false_neg  std_test_false_neg  \\\nK Nearest Neighbours                            11.4            0.800000   \nSupport Vector Machines                         11.8            0.400000   \nGaussian Process                                11.8            0.400000   \nRandom Forest Classifier                        11.8            0.400000   \nGradient Boosting Classifier                    11.4            0.489898   \nAda Boost classifier                            11.8            0.400000   \nGaussian Naieve Bayes                           10.8            0.979796   \nLogistic Regression                             11.8            0.400000   \nQuadratic Discriminant Analysis                 11.6            0.489898   \n\n                                 mean_train_false_neg  std_train_false_neg  \nK Nearest Neighbours                              0.0             0.000000  \nSupport Vector Machines                          47.2             0.400000  \nGaussian Process                                 47.2             0.400000  \nRandom Forest Classifier                         46.2             1.166190  \nGradient Boosting Classifier                     37.6             1.496663  \nAda Boost classifier                             46.4             0.800000  \nGaussian Naieve Bayes                            38.6             2.244994  \nLogistic Regression                              47.2             0.400000  \nQuadratic Discriminant Analysis                  43.8             3.919184  \n\n[9 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_test_accuracy</th>\n      <th>std_test_accuracy</th>\n      <th>mean_train_accuracy</th>\n      <th>std_train_accuracy</th>\n      <th>mean_test_recall</th>\n      <th>std_test_recall</th>\n      <th>mean_train_recall</th>\n      <th>std_train_recall</th>\n      <th>mean_test_precision</th>\n      <th>std_test_precision</th>\n      <th>...</th>\n      <th>mean_train_true_neg</th>\n      <th>std_train_true_neg</th>\n      <th>mean_test_false_pos</th>\n      <th>std_test_false_pos</th>\n      <th>mean_train_false_pos</th>\n      <th>std_train_false_pos</th>\n      <th>mean_test_false_neg</th>\n      <th>std_test_false_neg</th>\n      <th>mean_train_false_neg</th>\n      <th>std_train_false_neg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>K Nearest Neighbours</th>\n      <td>0.834783</td>\n      <td>0.011594</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.034848</td>\n      <td>0.042748</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.400000</td>\n      <td>0.489898</td>\n      <td>...</td>\n      <td>228.8</td>\n      <td>0.4000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.4</td>\n      <td>0.800000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Support Vector Machines</th>\n      <td>0.828986</td>\n      <td>0.005797</td>\n      <td>0.828986</td>\n      <td>0.001449</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>228.8</td>\n      <td>0.4000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.8</td>\n      <td>0.400000</td>\n      <td>47.2</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>Gaussian Process</th>\n      <td>0.828986</td>\n      <td>0.005797</td>\n      <td>0.828986</td>\n      <td>0.001449</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>228.8</td>\n      <td>0.4000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.8</td>\n      <td>0.400000</td>\n      <td>47.2</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>Random Forest Classifier</th>\n      <td>0.828986</td>\n      <td>0.005797</td>\n      <td>0.832609</td>\n      <td>0.004225</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.021099</td>\n      <td>0.026775</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>228.8</td>\n      <td>0.4000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.8</td>\n      <td>0.400000</td>\n      <td>46.2</td>\n      <td>1.166190</td>\n    </tr>\n    <tr>\n      <th>Gradient Boosting Classifier</th>\n      <td>0.831884</td>\n      <td>0.007100</td>\n      <td>0.863768</td>\n      <td>0.005423</td>\n      <td>0.033333</td>\n      <td>0.040825</td>\n      <td>0.203457</td>\n      <td>0.029255</td>\n      <td>0.400000</td>\n      <td>0.489898</td>\n      <td>...</td>\n      <td>228.8</td>\n      <td>0.4000</td>\n      <td>0.2</td>\n      <td>0.400000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.4</td>\n      <td>0.489898</td>\n      <td>37.6</td>\n      <td>1.496663</td>\n    </tr>\n    <tr>\n      <th>Ada Boost classifier</th>\n      <td>0.828986</td>\n      <td>0.005797</td>\n      <td>0.831884</td>\n      <td>0.002899</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.016933</td>\n      <td>0.015899</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>228.8</td>\n      <td>0.4000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.8</td>\n      <td>0.400000</td>\n      <td>46.4</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <th>Gaussian Naieve Bayes</th>\n      <td>0.797101</td>\n      <td>0.022452</td>\n      <td>0.830435</td>\n      <td>0.009559</td>\n      <td>0.083333</td>\n      <td>0.091287</td>\n      <td>0.182358</td>\n      <td>0.044308</td>\n      <td>0.219048</td>\n      <td>0.182201</td>\n      <td>...</td>\n      <td>220.6</td>\n      <td>2.6533</td>\n      <td>3.2</td>\n      <td>1.600000</td>\n      <td>8.2</td>\n      <td>2.481935</td>\n      <td>10.8</td>\n      <td>0.979796</td>\n      <td>38.6</td>\n      <td>2.244994</td>\n    </tr>\n    <tr>\n      <th>Logistic Regression</th>\n      <td>0.828986</td>\n      <td>0.005797</td>\n      <td>0.828986</td>\n      <td>0.001449</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>228.8</td>\n      <td>0.4000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.8</td>\n      <td>0.400000</td>\n      <td>47.2</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <th>Quadratic Discriminant Analysis</th>\n      <td>0.817391</td>\n      <td>0.011594</td>\n      <td>0.841304</td>\n      <td>0.014200</td>\n      <td>0.016667</td>\n      <td>0.033333</td>\n      <td>0.071277</td>\n      <td>0.089741</td>\n      <td>0.066667</td>\n      <td>0.133333</td>\n      <td>...</td>\n      <td>228.8</td>\n      <td>0.4000</td>\n      <td>1.0</td>\n      <td>0.894427</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>11.6</td>\n      <td>0.489898</td>\n      <td>43.8</td>\n      <td>3.919184</td>\n    </tr>\n  </tbody>\n</table>\n<p>9 rows Ã— 28 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"../data/train_test_data/\"\n",
    "\n",
    "X_train_res_ohe = pd.read_pickle(data_dir + \"X_train_res_ohe.pkl\")\n",
    "X_train_res_ohe_scaled = pd.read_pickle(data_dir + \"X_train_res_ohe_scaled.pkl\")\n",
    "y_train_res = pd.read_pickle(data_dir + \"y_train_res.pkl\")\n",
    "\n",
    "techniques_dict = {'K Nearest Neighbours': nns, 'Support Vector Machines': svm,\n",
    "                   'Gaussian Process': gp, 'Random Forest Classifier': rfc,\n",
    "                   'Gradient Boosting Classifier': gbc,  'Ada Boost classifier': ab,\n",
    "                   'Gaussian Naieve Bayes': nb, 'Logistic Regression': lr,\n",
    "                   'Quadratic Discriminant Analysis': qda}\n",
    "\n",
    "res_cv_results_list = []\n",
    "res_best_params_dict = {}\n",
    "for model_type, cv_model_func in techniques_dict.items():\n",
    "    print(f\"fitting {model_type}......\")\n",
    "    if cv_model_func in [nns, svm, gp, lr, lda, qda]:\n",
    "        best_params, cv_results = cv_model_func(X_train_res_ohe_scaled, y_train_res)\n",
    "        res_best_params_dict[model_type] = best_params\n",
    "        res_cv_results_list.append(cv_results)\n",
    "    else: # don't normalise x\n",
    "        best_params, cv_results = cv_model_func(X_train_res_ohe, y_train_res)\n",
    "        res_best_params_dict[model_type] = best_params\n",
    "        res_cv_results_list.append(cv_results)\n",
    "    print(\"done.\")\n",
    "\n",
    "res_cv_results_df = pd.DataFrame(res_cv_results_list,\n",
    "                                 index=techniques_dict.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 mean_test_accuracy  std_test_accuracy  \\\nK Nearest Neighbours                       0.799161           0.091665   \nSupport Vector Machines                    0.748513           0.109712   \nGaussian Process                           0.804546           0.129062   \nRandom Forest Classifier                   0.828955           0.126832   \nGradient Boosting Classifier               0.846499           0.130142   \nAda Boost classifier                       0.797529           0.114798   \nGaussian Naieve Bayes                      0.725782           0.125505   \nLogistic Regression                        0.750328           0.119565   \nQuadratic Discriminant Analysis            0.683738           0.111873   \n\n                                 mean_train_accuracy  std_train_accuracy  \\\nK Nearest Neighbours                        0.949752            0.022145   \nSupport Vector Machines                     0.847046            0.034454   \nGaussian Process                            0.991260            0.003654   \nRandom Forest Classifier                    0.909100            0.014866   \nGradient Boosting Classifier                1.000000            0.000000   \nAda Boost classifier                        0.926595            0.024814   \nGaussian Naieve Bayes                       0.766185            0.031478   \nLogistic Regression                         0.840494            0.035037   \nQuadratic Discriminant Analysis             0.753954            0.028103   \n\n                                 mean_test_recall  std_test_recall  \\\nK Nearest Neighbours                     0.824924         0.211814   \nSupport Vector Machines                  0.803690         0.229235   \nGaussian Process                         0.789837         0.308617   \nRandom Forest Classifier                 0.873866         0.218453   \nGradient Boosting Classifier             0.828252         0.318266   \nAda Boost classifier                     0.817846         0.269530   \nGaussian Naieve Bayes                    0.828252         0.239460   \nLogistic Regression                      0.810829         0.256861   \nQuadratic Discriminant Analysis          0.866788         0.205733   \n\n                                 mean_train_recall  std_train_recall  \\\nK Nearest Neighbours                      0.899456          0.044329   \nSupport Vector Machines                   0.899460          0.037613   \nGaussian Process                          0.995629          0.003906   \nRandom Forest Classifier                  0.947548          0.026785   \nGradient Boosting Classifier              1.000000          0.000000   \nAda Boost classifier                      0.934444          0.030247   \nGaussian Naieve Bayes                     0.888968          0.036558   \nLogistic Regression                       0.883724          0.043071   \nQuadratic Discriminant Analysis           0.944055          0.033759   \n\n                                 mean_test_precision  std_test_precision  \\\nK Nearest Neighbours                        0.776295            0.046845   \nSupport Vector Machines                     0.705949            0.082772   \nGaussian Process                            0.790737            0.063836   \nRandom Forest Classifier                    0.789074            0.100830   \nGradient Boosting Classifier                0.869949            0.043754   \nAda Boost classifier                        0.771731            0.063102   \nGaussian Naieve Bayes                       0.668393            0.104228   \nLogistic Regression                         0.700898            0.094759   \nQuadratic Discriminant Analysis             0.625408            0.086105   \n\n                                 mean_train_precision  std_train_precision  \\\nK Nearest Neighbours                         1.000000             0.000000   \nSupport Vector Machines                      0.814010             0.030110   \nGaussian Process                             0.987002             0.003872   \nRandom Forest Classifier                     0.880361             0.018717   \nGradient Boosting Classifier                 1.000000             0.000000   \nAda Boost classifier                         0.919970             0.022535   \nGaussian Naieve Bayes                        0.713578             0.024141   \nLogistic Regression                          0.813002             0.027682   \nQuadratic Discriminant Analysis              0.684800             0.024741   \n\n                                 mean_test_true_pos  std_test_true_pos  \\\nK Nearest Neighbours                           47.2          12.139193   \nSupport Vector Machines                        46.0          13.190906   \nGaussian Process                               45.2          17.656727   \nRandom Forest Classifier                       50.0          12.521981   \nGradient Boosting Classifier                   47.4          18.216476   \nAda Boost classifier                           46.8          15.432433   \nGaussian Naieve Bayes                          47.4          13.749182   \nLogistic Regression                            46.4          14.718696   \nQuadratic Discriminant Analysis                49.6          11.825396   \n\n                                 mean_train_true_pos  std_train_true_pos  \\\nK Nearest Neighbours                           205.8           10.244999   \nSupport Vector Machines                        205.8            8.704022   \nGaussian Process                               227.8            0.979796   \nRandom Forest Classifier                       216.8            6.177378   \nGradient Boosting Classifier                   228.8            0.400000   \nAda Boost classifier                           213.8            6.910861   \nGaussian Naieve Bayes                          203.4            8.475848   \nLogistic Regression                            202.2            9.947864   \nQuadratic Discriminant Analysis                216.0            7.745967   \n\n                                 mean_test_true_neg  std_test_true_neg  \\\nK Nearest Neighbours                           44.2           2.925748   \nSupport Vector Machines                        39.6           1.019804   \nGaussian Process                               46.8           3.370460   \nRandom Forest Classifier                       44.8           4.166533   \nGradient Boosting Classifier                   49.4           4.841487   \nAda Boost classifier                           44.4           4.317407   \nGaussian Naieve Bayes                          35.6           2.244994   \nLogistic Regression                            39.4           2.416609   \nQuadratic Discriminant Analysis                28.6           5.083306   \n\n                                 mean_train_true_neg  std_train_true_neg  \\\nK Nearest Neighbours                           228.8            0.400000   \nSupport Vector Machines                        181.8            7.249828   \nGaussian Process                               225.8            0.748331   \nRandom Forest Classifier                       199.2            5.600000   \nGradient Boosting Classifier                   228.8            0.400000   \nAda Boost classifier                           210.2            5.035871   \nGaussian Naieve Bayes                          147.2            6.400000   \nLogistic Regression                            182.4            6.086050   \nQuadratic Discriminant Analysis                129.0           11.798305   \n\n                                 mean_test_false_pos  std_test_false_pos  \\\nK Nearest Neighbours                            13.0            2.683282   \nSupport Vector Machines                         17.6            0.800000   \nGaussian Process                                10.4            3.006659   \nRandom Forest Classifier                        12.4            4.317407   \nGradient Boosting Classifier                     7.8            4.534314   \nAda Boost classifier                            12.8            4.069398   \nGaussian Naieve Bayes                           21.6            2.332381   \nLogistic Regression                             17.8            2.227106   \nQuadratic Discriminant Analysis                 28.6            5.083306   \n\n                                 mean_train_false_pos  std_train_false_pos  \\\nK Nearest Neighbours                              0.0             0.000000   \nSupport Vector Machines                          47.0             7.615773   \nGaussian Process                                  3.0             0.894427   \nRandom Forest Classifier                         29.6             5.462600   \nGradient Boosting Classifier                      0.0             0.000000   \nAda Boost classifier                             18.6             5.314132   \nGaussian Naieve Bayes                            81.6             6.740920   \nLogistic Regression                              46.4             6.468385   \nQuadratic Discriminant Analysis                  99.8            11.956588   \n\n                                 mean_test_false_neg  std_test_false_neg  \\\nK Nearest Neighbours                            10.0           12.066483   \nSupport Vector Machines                         11.2           13.059862   \nGaussian Process                                12.0           17.584084   \nRandom Forest Classifier                         7.2           12.448293   \nGradient Boosting Classifier                     9.8           18.137254   \nAda Boost classifier                            10.4           15.357083   \nGaussian Naieve Bayes                            9.8           13.644046   \nLogistic Regression                             10.8           14.634207   \nQuadratic Discriminant Analysis                  7.6           11.723481   \n\n                                 mean_train_false_neg  std_train_false_neg  \nK Nearest Neighbours                             23.0            10.139033  \nSupport Vector Machines                          23.0             8.602325  \nGaussian Process                                  1.0             0.894427  \nRandom Forest Classifier                         12.0             6.131884  \nGradient Boosting Classifier                      0.0             0.000000  \nAda Boost classifier                             15.0             6.928203  \nGaussian Naieve Bayes                            25.4             8.357033  \nLogistic Regression                              26.6             9.850888  \nQuadratic Discriminant Analysis                  12.8             7.730459  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_test_accuracy</th>\n      <th>std_test_accuracy</th>\n      <th>mean_train_accuracy</th>\n      <th>std_train_accuracy</th>\n      <th>mean_test_recall</th>\n      <th>std_test_recall</th>\n      <th>mean_train_recall</th>\n      <th>std_train_recall</th>\n      <th>mean_test_precision</th>\n      <th>std_test_precision</th>\n      <th>mean_train_precision</th>\n      <th>std_train_precision</th>\n      <th>mean_test_true_pos</th>\n      <th>std_test_true_pos</th>\n      <th>mean_train_true_pos</th>\n      <th>std_train_true_pos</th>\n      <th>mean_test_true_neg</th>\n      <th>std_test_true_neg</th>\n      <th>mean_train_true_neg</th>\n      <th>std_train_true_neg</th>\n      <th>mean_test_false_pos</th>\n      <th>std_test_false_pos</th>\n      <th>mean_train_false_pos</th>\n      <th>std_train_false_pos</th>\n      <th>mean_test_false_neg</th>\n      <th>std_test_false_neg</th>\n      <th>mean_train_false_neg</th>\n      <th>std_train_false_neg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>K Nearest Neighbours</th>\n      <td>0.799161</td>\n      <td>0.091665</td>\n      <td>0.949752</td>\n      <td>0.022145</td>\n      <td>0.824924</td>\n      <td>0.211814</td>\n      <td>0.899456</td>\n      <td>0.044329</td>\n      <td>0.776295</td>\n      <td>0.046845</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>47.2</td>\n      <td>12.139193</td>\n      <td>205.8</td>\n      <td>10.244999</td>\n      <td>44.2</td>\n      <td>2.925748</td>\n      <td>228.8</td>\n      <td>0.400000</td>\n      <td>13.0</td>\n      <td>2.683282</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>10.0</td>\n      <td>12.066483</td>\n      <td>23.0</td>\n      <td>10.139033</td>\n    </tr>\n    <tr>\n      <th>Support Vector Machines</th>\n      <td>0.748513</td>\n      <td>0.109712</td>\n      <td>0.847046</td>\n      <td>0.034454</td>\n      <td>0.803690</td>\n      <td>0.229235</td>\n      <td>0.899460</td>\n      <td>0.037613</td>\n      <td>0.705949</td>\n      <td>0.082772</td>\n      <td>0.814010</td>\n      <td>0.030110</td>\n      <td>46.0</td>\n      <td>13.190906</td>\n      <td>205.8</td>\n      <td>8.704022</td>\n      <td>39.6</td>\n      <td>1.019804</td>\n      <td>181.8</td>\n      <td>7.249828</td>\n      <td>17.6</td>\n      <td>0.800000</td>\n      <td>47.0</td>\n      <td>7.615773</td>\n      <td>11.2</td>\n      <td>13.059862</td>\n      <td>23.0</td>\n      <td>8.602325</td>\n    </tr>\n    <tr>\n      <th>Gaussian Process</th>\n      <td>0.804546</td>\n      <td>0.129062</td>\n      <td>0.991260</td>\n      <td>0.003654</td>\n      <td>0.789837</td>\n      <td>0.308617</td>\n      <td>0.995629</td>\n      <td>0.003906</td>\n      <td>0.790737</td>\n      <td>0.063836</td>\n      <td>0.987002</td>\n      <td>0.003872</td>\n      <td>45.2</td>\n      <td>17.656727</td>\n      <td>227.8</td>\n      <td>0.979796</td>\n      <td>46.8</td>\n      <td>3.370460</td>\n      <td>225.8</td>\n      <td>0.748331</td>\n      <td>10.4</td>\n      <td>3.006659</td>\n      <td>3.0</td>\n      <td>0.894427</td>\n      <td>12.0</td>\n      <td>17.584084</td>\n      <td>1.0</td>\n      <td>0.894427</td>\n    </tr>\n    <tr>\n      <th>Random Forest Classifier</th>\n      <td>0.828955</td>\n      <td>0.126832</td>\n      <td>0.909100</td>\n      <td>0.014866</td>\n      <td>0.873866</td>\n      <td>0.218453</td>\n      <td>0.947548</td>\n      <td>0.026785</td>\n      <td>0.789074</td>\n      <td>0.100830</td>\n      <td>0.880361</td>\n      <td>0.018717</td>\n      <td>50.0</td>\n      <td>12.521981</td>\n      <td>216.8</td>\n      <td>6.177378</td>\n      <td>44.8</td>\n      <td>4.166533</td>\n      <td>199.2</td>\n      <td>5.600000</td>\n      <td>12.4</td>\n      <td>4.317407</td>\n      <td>29.6</td>\n      <td>5.462600</td>\n      <td>7.2</td>\n      <td>12.448293</td>\n      <td>12.0</td>\n      <td>6.131884</td>\n    </tr>\n    <tr>\n      <th>Gradient Boosting Classifier</th>\n      <td>0.846499</td>\n      <td>0.130142</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.828252</td>\n      <td>0.318266</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.869949</td>\n      <td>0.043754</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>47.4</td>\n      <td>18.216476</td>\n      <td>228.8</td>\n      <td>0.400000</td>\n      <td>49.4</td>\n      <td>4.841487</td>\n      <td>228.8</td>\n      <td>0.400000</td>\n      <td>7.8</td>\n      <td>4.534314</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>9.8</td>\n      <td>18.137254</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Ada Boost classifier</th>\n      <td>0.797529</td>\n      <td>0.114798</td>\n      <td>0.926595</td>\n      <td>0.024814</td>\n      <td>0.817846</td>\n      <td>0.269530</td>\n      <td>0.934444</td>\n      <td>0.030247</td>\n      <td>0.771731</td>\n      <td>0.063102</td>\n      <td>0.919970</td>\n      <td>0.022535</td>\n      <td>46.8</td>\n      <td>15.432433</td>\n      <td>213.8</td>\n      <td>6.910861</td>\n      <td>44.4</td>\n      <td>4.317407</td>\n      <td>210.2</td>\n      <td>5.035871</td>\n      <td>12.8</td>\n      <td>4.069398</td>\n      <td>18.6</td>\n      <td>5.314132</td>\n      <td>10.4</td>\n      <td>15.357083</td>\n      <td>15.0</td>\n      <td>6.928203</td>\n    </tr>\n    <tr>\n      <th>Gaussian Naieve Bayes</th>\n      <td>0.725782</td>\n      <td>0.125505</td>\n      <td>0.766185</td>\n      <td>0.031478</td>\n      <td>0.828252</td>\n      <td>0.239460</td>\n      <td>0.888968</td>\n      <td>0.036558</td>\n      <td>0.668393</td>\n      <td>0.104228</td>\n      <td>0.713578</td>\n      <td>0.024141</td>\n      <td>47.4</td>\n      <td>13.749182</td>\n      <td>203.4</td>\n      <td>8.475848</td>\n      <td>35.6</td>\n      <td>2.244994</td>\n      <td>147.2</td>\n      <td>6.400000</td>\n      <td>21.6</td>\n      <td>2.332381</td>\n      <td>81.6</td>\n      <td>6.740920</td>\n      <td>9.8</td>\n      <td>13.644046</td>\n      <td>25.4</td>\n      <td>8.357033</td>\n    </tr>\n    <tr>\n      <th>Logistic Regression</th>\n      <td>0.750328</td>\n      <td>0.119565</td>\n      <td>0.840494</td>\n      <td>0.035037</td>\n      <td>0.810829</td>\n      <td>0.256861</td>\n      <td>0.883724</td>\n      <td>0.043071</td>\n      <td>0.700898</td>\n      <td>0.094759</td>\n      <td>0.813002</td>\n      <td>0.027682</td>\n      <td>46.4</td>\n      <td>14.718696</td>\n      <td>202.2</td>\n      <td>9.947864</td>\n      <td>39.4</td>\n      <td>2.416609</td>\n      <td>182.4</td>\n      <td>6.086050</td>\n      <td>17.8</td>\n      <td>2.227106</td>\n      <td>46.4</td>\n      <td>6.468385</td>\n      <td>10.8</td>\n      <td>14.634207</td>\n      <td>26.6</td>\n      <td>9.850888</td>\n    </tr>\n    <tr>\n      <th>Quadratic Discriminant Analysis</th>\n      <td>0.683738</td>\n      <td>0.111873</td>\n      <td>0.753954</td>\n      <td>0.028103</td>\n      <td>0.866788</td>\n      <td>0.205733</td>\n      <td>0.944055</td>\n      <td>0.033759</td>\n      <td>0.625408</td>\n      <td>0.086105</td>\n      <td>0.684800</td>\n      <td>0.024741</td>\n      <td>49.6</td>\n      <td>11.825396</td>\n      <td>216.0</td>\n      <td>7.745967</td>\n      <td>28.6</td>\n      <td>5.083306</td>\n      <td>129.0</td>\n      <td>11.798305</td>\n      <td>28.6</td>\n      <td>5.083306</td>\n      <td>99.8</td>\n      <td>11.956588</td>\n      <td>7.6</td>\n      <td>11.723481</td>\n      <td>12.8</td>\n      <td>7.730459</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cv_results_df = pd.DataFrame(res_cv_results_list,\n",
    "                                 index=techniques_dict.keys())\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "res_cv_results_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is A\n",
      "b is B\n",
      "the rest is {'d': 'C', 'e': 'D', 'f': 'Â£'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def functioney(a, b, **kwargs):\n",
    "\n",
    "\n",
    "functioney(\"A\", \"B\", d=\"C\", e=\"D\", f=\"Â£\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}