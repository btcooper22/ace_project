---
title: "Bootstrap Aggregation Assessment"
author: "Ben Cooper"
date: "22/04/2021"
output: pdf_document
---

```{r Packages}
require(readr)
require(caret)
require(glmnet)
require(foreach)
require(dplyr)
require(doParallel)
require(tools)
require(pROC)
require(ResourceSelection)
require(ggplot2)
require(tidyr)
require(tibble)
require(magrittr)
require(ggpol)
require(matrixStats)
require(bayestestR)
require(stringr)
require(janitor)
require(purrr)
require(progressr)
handlers(global = TRUE)

source("functions/inverse_logit.R")

boolean_clean <- function(x)
{
  return(
    x == "y"
  )
}
```

```{r Load and prepare data}
# Load data
results <- read_csv("data/ace_data_cooper_final.csv")

# Check for duplicates
duplicated_rowid <- results %>% 
  get_dupes(person_id, date_referred) %>% 
  group_by(person_id, date_referred) %>% 
  slice_max(rowid) %>% 
  ungroup() %>% 
  select(rowid) %>% 
  deframe()

# Cleaning results
results %<>%
  # Remove duplicaes
  filter(!rowid %in% duplicated_rowid) %>% 
  # Clean boolean values
  mutate(hospital_reqd = hospital_reqd == 1,
         safeguarding = boolean_clean(safeguarding),
         food_allergy = boolean_clean(food_allergy),
         drug_allergy = boolean_clean(drug_allergy),
         other_allergy = boolean_clean(other_allergy),
         ox_sat_low = boolean_clean(ox_sat_low),
         meets_ace_criteria = boolean_clean(meets_ace_criteria),
         mentions_asthma = boolean_clean(mentions_asthma),
         mentions_salbutamol = boolean_clean(mentions_salbutamol)) %>% 
  # Scale numeric variables
  mutate(ox_sat = scale(ox_sat),
         temp = scale(temp),
         resp_rate = scale(resp_rate),
         heart_rate = scale(heart_rate)) %>% 
  # Add new variables
  mutate(referral_from_gp = referral_from == "gp",
         abnormal_resp_rate = apls_resp_rate_cat != "normal",
         gut_feeling_abnormal = gut_feeling != "well",
         abnormal_heart_rate = ace_heart_rate_cat != "normal")

# Build vector of acceptable features
feature_id <- which(names(results) %in% c("hospital_reqd", "age", "gender", "illness_severity", "activity_level",
                                    "ox_sat", "resp_rate", "heart_rate", "temp", "safeguarding", "food_allergy",
                                    "drug_allergy", "other_allergy", "meets_ace_criteria", "mentions_asthma",
                                    "mentions_salbutamol", "referral_from_gp", "abnormal_resp_rate",
                                    "gut_feeling_abnormal", "abnormal_heart_rate", "high_NO2" , "high_PM10",
                                    "high_CYPScore", "high_EduScore", "high_IDCScore", "eczema_any", "eczema_year",
                                    "eczema_6m", "respiratory_any", "bronchitis_any", "pneumonia_any", 
                                    "many_inhalers", "many_prednisolone_courses", "many_prednisolone_courses_year",
                                    "many_prednisolone_courses_6m", "prednisolone_1m", "prednisolone_year",
                                    "prednisolone_6m", "log_surgery_distance", "high_surgery_distance",   
                                    "high_log_surgery_distance", "high_hospital_distance",
                                    "high_log_hospital_distance", "high_vER_1y", "high_vGP_6m", "high_vGP_1y", 
                                    "high_vIP_6m", "high_vIP_1y", "high_vIP_3y", "high_vIP_total", "high_vOP_3y",
                                    "high_vXX_1m", "high_vXX_6m", "high_vXX_1y", "slow_bronchodilator_any",
                                    "slow_bronchodilator_year", "slow_bronchodilator_1m"))
names(results)[feature_id]

# Prepare parallel
psnice(value = 19)
n_cores <- 15
cl <- makeCluster(ifelse(detectCores() <= n_cores,
                          detectCores() - 1,
                          n_cores))
registerDoParallel(cl)
```

```{r Determine retained variables using lasso}
# Set parameters
lambda_seq <-  exp(seq(-1, -6, length = 100))

# Subsample dataset with replacement
lasso_df <- results %>% 
  select(all_of(feature_id)) %>% 
  na.omit()

# Build model components
x <- model.matrix(hospital_reqd~., lasso_df)[,-1]
y <- lasso_df$hospital_reqd

# Profile over range of lambda
lambda_profile <-  glmnet(x, y, alpha = 1, lambda = lambda_seq,
                          family = "binomial")

# Find lambda best matching 10epv
lambda_min <- lambda_profile$lambda[which.min(abs(8 - lambda_profile$df))]

# Fit model
lasso_model <- glmnet(x, y, alpha = 1, lambda = lambda_min,
                     family = "binomial")

# Output
lasso_model$beta %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  filter(s0 != 0)
```


```{r Bagging function}
# Test parameters
# df <- results
# nboot <- 100

bootstrap_aggregate <- function(df, nboot)
{
  # Fit model on bootstrapped dataset
  model_coefficients <- foreach(j = 1:nboot, .combine = "rbind",
                               .packages = c("dplyr", "caret",
                                             "foreach"),
                               .inorder = FALSE) %dopar%
  {
    set.seed(j)
    
    # Subsample dataset with replacement
    boot_df <- df %>% 
      group_by(hospital_reqd) %>% 
      slice_sample(prop = 0.75,
                   replace = TRUE) %>%
      ungroup()
    
    # Build model
    model_instance <- glm(hospital_reqd ~ ox_sat + eczema_any +
                            pneumonia_any + referral_from_gp +
                            mentions_asthma + high_NO2 +
                            slow_bronchodilator_year,
                          data = boot_df, family = "binomial")
    
    # Post-predict to determine threshold
    preds <- predict(model_instance, newdata = boot_df)
    
    tuning_df <- foreach(i = seq(-2.5,-0.5,0.05),
                         .combine = "rbind") %do%
      {
        boot_df$hospital_reqd_pred <- preds > i
        
        conMat <- confusionMatrix(boot_df$hospital_reqd_pred %>% as.factor(),
                                  boot_df$hospital_reqd %>% as.factor())
        
        data.frame(threshold = i,
                   balanced_accuracy = conMat[["byClass"]][["Balanced Accuracy"]])
      }
    threshold <- tuning_df$threshold[tuning_df$balanced_accuracy == max(tuning_df$balanced_accuracy)]
    
   t(as.data.frame(coef(model_instance))) %>% 
     cbind(threshold)
  }
  
  # Process output
  model_coefficients %<>% as_tibble()
  return(model_coefficients)
}
```

```{r Prediction function}
# Debug
# coef_df <- bootstrap_aggregate(results, 100)
# newdata <- results %>%
#   group_by(hospital_reqd) %>%
#   slice_sample(prop = 0.2,
#                replace = TRUE)

predict_from_bagging <- function(newdata, coef_df)
{
  predicted_classes <- foreach(i = 1:nrow(coef_df),.combine = "cbind") %do%
    {
      # Extract coeffcients
      coefs <- as.numeric(coef_df[i,])
      coefs[is.na(coefs)] <- 0
      names(coefs) <- names(coef_df)
      
      # Build equation
      pred_y <- coefs[1] + (newdata$ox_sat * coefs[2]) +
        (newdata$eczema_any * coefs[3]) +
        (newdata$pneumonia_any * coefs[4]) +
        (newdata$referral_from_gp * coefs[5]) +
        (newdata$mentions_asthma * coefs[6]) +
        (newdata$high_NO2 * coefs[7]) +
        (newdata$slow_bronchodilator_year * coefs[8])
      
      # Binarise predictions
      as.numeric(pred_y > coefs[9])
    }
  return(predicted_classes)
}
```

```{r Assessment function}
# Debug
# y <- newdata$hospital_reqd
# y_pred <- predict_from_bagging(newdata, coef_df)

model_assessment <- function(y, y_pred)
{
  # Generate confusion matrix from majority vote
  conMat <- confusionMatrix(factor(rowMedians(y_pred) == 1),
                            y %>% as.factor(),
                            positive = "TRUE")
  
  # Generate AUC
  roc_obj <- roc(response = y,
                 predictor = as.numeric(rowMedians(y_pred) == 1),
                 levels = c(FALSE, TRUE),
                 direction = "<")

  # Output
  return(
    data.frame(accuracy = conMat$overall[1],
               kappa = conMat$overall[2],
               sensitivity_recall = conMat$byClass[1],
               specificity = conMat$byClass[2],
               precision = conMat$byClass[5],
               positive_predictive_value = conMat$byClass[3],
               negative_predictive_value = conMat$byClass[4],
               detection_rate = conMat$byClass[9],
               detection_prevalence = conMat$byClass[10],
               F1 = conMat$byClass[7],
               balanced_accuracy = conMat$byClass[11],
               AUC = ifelse(roc_obj$auc < 0.5, 1-roc_obj$auc,
                            roc_obj$auc))
  )
}

```

```{r Main loop}
# Set up parameters 
nboot <- 1000
ncycles <- 1000

# Setup progress bar
handlers(list(
  handler_progress(
    format   = ":current/:total [:bar] :percent in :elapsed ETA: :eta",
    width    = 100,
    complete = "+"
  ))
)

# Main loop
loop_fun <- function(ncyc)
{
  prog <- progressor(along = 1:ncycles)
  foreach(k = 1:ncycles, .combine = "rbind") %do%
  {
    prog(sprintf("k=%g", k))
    #print(k)
    set.seed(k)
  
    # Partition data for training and validation
    patients_train <- results %>% 
      group_by(hospital_reqd) %>% 
      slice_sample(prop = 0.75)
    
    patients_validate <- results %>% 
      filter(!rowid %in% patients_train$rowid)
    
    # Train model
    model_collection <- bootstrap_aggregate(patients_train, nboot)
    
    # Store parameter estimates
    parameters <- model_collection %>% 
      pivot_longer(1:length(model_collection)) %>% 
      group_by(name) %>% 
      summarise(estimate = median(value)) %>% 
      pivot_wider(names_from = "name",
                  values_from = "estimate")
    
    # Predict from model collection
    predicted_admission <- predict_from_bagging(patients_validate, model_collection)
    
    # Assess predictions
    output <- model_assessment(y = patients_validate$hospital_reqd,
                     y_pred = predicted_admission)
    
    return(cbind(output, parameters))
  }
}
model_performance <- loop_fun(ncycles)

# Write file
write_rds(model_performance, "analysis/boostrap_aggregate_additional.RDS")
```