---
title: "Initial Large Analysis"
author: "Ben Cooper"
date: "14/04/2021"
output: pdf_document
---

```{r setup, include=FALSE}
require(readr)
require(caret)
require(glmnet)
require(foreach)
require(dplyr)
require(doParallel)
require(tools)
require(ROCR)
require(ResourceSelection)
require(ggplot2)
require(tidyr)
require(tibble)
require(magrittr)
require(ggpol)

source("functions/inverse_logit.R")
```

So here, to goal is to 'replicate' Sam's work. By which I mean 'use lasso logistic regression to develop and test a model', but here with the additional data added in. The assumption/hypothesis is that this still won't have that good predictive power.

```{r Load and prepare data}
# Load data
results <- read.csv("data/ace_data_april21.csv")
results$id <- 1:nrow(results)

# Build vector of acceptable features
feature_id <- c(2:5, 7:21, 23:31)
names(results)[feature_id]

# Clean
results$hospital_reqd <- results$hospital_reqd == 1

# Scale
results$ox_sat <- scale(results$ox_sat)
results$temp <- scale(results$temp)
results$resp_rate <- scale(results$resp_rate)
results$heart_rate <- scale(results$heart_rate)
```

```{r Determine lambda using full dataset}
# Select predictor and outcome vectors
x <- model.matrix(hospital_reqd~., results[,feature_id])[,-1]
y <- results$hospital_reqd

# Determine lambda
cv <- cv.glmnet(x, y, alpha = 1,
                family = "binomial", type.measure = "auc")
```

```{r Bootstrap variable selection}
# Set parameters
nboot <- 1000
lambda_seq <-  exp(seq(-1, -6, length = 100))

# Prepare parallel options
psnice(value = 19)
n_cores <- 15
cl <- makeCluster(ifelse(detectCores() <= n_cores,
                          detectCores() - 1,
                          n_cores))
registerDoParallel(cl)

# Loop for bootstraps
boot_results <- foreach(i = 1:nboot, .combine = "rbind",
                        .packages = c("dplyr", "caret",
                                      "glmnet")) %dopar%
  {
    set.seed(i)
    
    # Split data
    train_df <- results %>% 
      group_by(hospital_reqd) %>% 
      slice_sample(prop = 0.5,
                   replace = TRUE) %>% 
      select(all_of(feature_id))
    
    # Remove variables with only one factor level
    levels_list <- apply(train_df, 2, function(x){length(unique(x))})
    train_df <- train_df[,levels_list > 1]
    
    # Build model components
    x <- model.matrix(hospital_reqd~., train_df)[,-1]
    y <- train_df$hospital_reqd
    
    # Profile over range of lambda
    lambda_profile <-  glmnet(x, y, alpha = 1, lambda = lambda_seq,
                         family = "binomial")
    
    # Find lambda best matching 10epv
    lambda_min <- lambda_profile$lambda[which.min(abs(8 - lambda_profile$df))]
    
    # Fit model
    boot_model <- glmnet(x, y, alpha = 1, lambda = lambda_min,
                         family = "binomial")
    
        # Output
    output <- as.matrix(boot_model$beta) %>% 
      as.data.frame()
    output$var <- rownames(output)
    output$iteration <- i
    output
  }
stopCluster(cl)

# Identify retained variables
boot_results %>%
  group_by(var) %>% 
  summarise(prop = mean(s0 != 0)) %>% 
  #filter(prop > 0.8) %>% 
  mutate(prop = round(prop, 2)) %>% 
  arrange(desc(prop)) %>% 
  slice_head(n = 8) %>% 
  as.data.frame()

# Add new variables
results %<>% 
  mutate(referral_from_gp = referral_from == "gp",
         abnormal_resp_rate = apls_resp_rate_cat != "normal")
```

```{r Determine model coefficients}
# Prepare parallel
cl <- makeCluster(ifelse(detectCores() <= n_cores,
                          detectCores() - 1,
                          n_cores))
registerDoParallel(cl)

model_performance <- foreach(j = 1:nboot, .combine = "rbind",
                               .packages = c("dplyr", "ROCR",
                                             "ResourceSelection")) %dopar%
  {
    set.seed(j)

    # Set splits
    train_df <- results %>% 
      group_by(hospital_reqd) %>% 
      slice_sample(prop = 0.75,
                   replace = TRUE) %>%
      ungroup()
    
    # Build model
    model_instance <- glm(hospital_reqd ~ ox_sat + mentions_asthma +
                            referral_from_gp + mentions_salbutamol +
                            illness_severity + abnormal_resp_rate,
                          data = train_df, family = "binomial")
    
   t(as.data.frame(coef(model_instance)))
  }
stopCluster(cl)

# Plot coefficients
model_performance %>% 
  as_tibble() %>% 
  pivot_longer(1:7) %>% 
  ggplot(aes(x = value))+
  geom_density(fill = "Gray80")+
  facet_wrap(~name, scales = "free")+
  theme_classic()

# Plot coefficients x2
model_performance %>% 
  as_tibble() %>% 
  pivot_longer(1:7) %>% 
  filter(name != "(Intercept)") %>% 
  ggplot(aes(x = value))+
  geom_density(aes(fill = name),
               alpha = 0.7)+
  theme_classic()+
  scale_fill_brewer(palette = "Set1",
                    name = "")+
  theme(legend.position = "top",
        axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank())+
  labs(x = "Coefficient", y = "")+
  geom_vline(xintercept = 0,
             linetype = "dashed")
```

```{r Assess model performance}
# Extract coefficients
model_coefficients <- model_performance %>% 
  as_tibble() %>% 
  pivot_longer(1:7) %>% 
  group_by(name) %>% 
  summarise(coef = median(value)) %>% 
  pivot_wider(names_from = "name",
              values_from = "coef")

coefs <- as.numeric(model_coefficients[1,])
names(coefs) <- names(model_coefficients)

# Build equation
pred_y <- coefs[1] + (results$abnormal_resp_rate * coefs[2]) +
  ((results$illness_severity == "moderate") * coefs[3]) +
  ((results$mentions_asthma == "y") * coefs[4]) +
  ((results$mentions_salbutamol == "y") * coefs[5]) +
  (results$referral_from_gp * coefs[7]) +
  (results$ox_sat * coefs[6])

# Predict
probs_df <- 
  data.frame(probs = inverse_logit(pred_y),
             outcome = results$hospital_reqd)

# Plot predictions
probs_df %>% 
  ggplot(aes(outcome, probs))+
  geom_boxjitter(aes(fill = outcome),
                 jitter.shape = 21,
                 jitter.size = 2,
                 outlier.shape = NA,
                 jitter.params = list(height = 0,
                                      width = 0.1),
                 jitter.alpha = 0.8,
                 alpha = 0.8)+
  scale_fill_brewer(palette = "Set1")+
  theme_classic(20)+
  theme(legend.position = "none")+
  labs(x = "Hospital required",
       y = "Admission probability")

# Discrimination
pred <- prediction(probs_df$probs,
                   probs_df$outcome)
performance(pred, measure = "auc")@y.values[[1]]

# Plot
plot(performance(pred, "tpr", "fpr"),
     col = "red")
abline(0, 1)

# Calibration
hoslem.test(probs_df$outcome,
            probs_df$probs, g = 10)


```



```{r Assess model performance in loop}

valid_df <- results %>% 
  filter(id %in% train_df$id == FALSE)

# Predict
probs_df <- 
  data.frame(probs = predict(model_instance, 
                             newdata = valid_df),
             outcome = valid_df$hospital_reqd) %>% 
  mutate(probs = inverse_logit(probs))

# Discrimination
pred <- prediction(probs_df$probs,
                   probs_df$outcome)
auc <- performance(pred, measure = "auc")@y.values[[1]]

# Calibration
cal <- hoslem.test(probs_df$outcome,
                   probs_df$probs, g = 10)$statistic

# Output
data.frame(sample = j,
           discrim = auc,
           calib = cal %>% unname())
```

